# MKT DCS Staging

Marketing Data Collection System - Databricks Notebooks é¡¹ç›®ã€‚

æœ¬é¡¹ç›®åŒ…å«ç”¨äºä»å„å¹¿å‘Šæ¸ é“æ”¶é›†æ¶ˆè€—æŠ¥å‘Šå’Œä¸Šä¼ å—ä¼—æ•°æ®çš„ Databricks Notebooksã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼šæ·»åŠ æ–°æ¸ é“

> 5 åˆ†é’Ÿå¿«é€Ÿæ·»åŠ ä¸€ä¸ªæ–°çš„å¹¿å‘Šæ¸ é“æŠ¥å‘Š

### Step 1: å¤åˆ¶æ¨¡æ¿

å¤åˆ¶ `aarki_spend_report.py` ä½œä¸ºæ¨¡æ¿ï¼ˆæœ€ç®€æ´çš„ç¤ºä¾‹ï¼‰

### Step 2: ä¿®æ”¹é…ç½®

```python
# --- [é…ç½®å‚æ•°] ---
_AD_NETWORK = 'your_network'   # æ¸ é“åï¼ˆå°å†™ï¼Œç”¨äºæ–‡ä»¶åå’Œè·¯å¾„ï¼‰
_AD_TYPE = 'spend'              # æŠ¥å‘Šç±»å‹: spend/income/iap/mediation/attribution
_DATE_RANGE = 7                 # å›æº¯å¤©æ•°
```

### Step 3: ä¿®æ”¹ API è¯·æ±‚

```python
req_opt = dict(
    url='https://api.your-network.com/report',
    params={'api_key': cfg.get('api_key'), 'start': start_ds, 'end': end_ds},
    headers={'Authorization': f'Bearer {cfg.get("token")}'}  # å¯é€‰
)

helper.fetch_report(
    ad_network=_AD_NETWORK,
    ad_type=_AD_TYPE,
    exc_ds=ds,
    start_ds=start_ds,
    end_ds=end_ds,
    **req_opt
)
```

### Step 4: æ·»åŠ å¯†é’¥é…ç½®

```bash
databricks secrets put --scope dcs-staging-secret --key secret_your_network
# è¾“å…¥ JSON: {"api_key": "xxx", "token": "xxx"}
```

**å°±è¿™ä¹ˆç®€å•ï¼** ğŸ‰ ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†ï¼š
- âœ… æ•°æ®æ ¼å¼æ£€æµ‹ï¼ˆCSV/JSON/JSONL/APIå“åº”ï¼‰
- âœ… æµå¼ä¸‹è½½ï¼ˆå¤§æ–‡ä»¶ä¸ä¼š OOMï¼‰
- âœ… è½¬æ¢ä¸º JSONL æ ¼å¼
- âœ… ä¸Šä¼ åˆ° S3
- âœ… ä¿å­˜æœ¬åœ°é¢„è§ˆï¼ˆstaging æ¨¡å¼ï¼‰

ğŸ‘‰ è¯¦ç»†å¼€å‘è§„èŒƒè¯·çœ‹ [NOTEBOOK_GUIDELINES.md](./NOTEBOOK_GUIDELINES.md)

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
mkt-dcs-staging/
â”œâ”€â”€ README.md                      # æœ¬æ–‡æ¡£
â”œâ”€â”€ NOTEBOOK_GUIDELINES.md         # Notebook å¼€å‘è§„èŒƒï¼ˆå¿…è¯»ï¼‰
â”œâ”€â”€ config/
â”‚   â””â”€â”€ dag_id_to_s3_paths.json    # S3 è·¯å¾„å‚è€ƒæ–‡æ¡£ï¼ˆä»…ä¾›å‚è€ƒï¼‰
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config_manager.py          # é…ç½®ç®¡ç†å™¨ï¼ˆç¯å¢ƒæ¨¡å¼ã€å¯†é’¥è¯»å–ï¼‰
â”‚   â”œâ”€â”€ data_parser.py             # ğŸ†• æ•°æ®æ ¼å¼è§£æå™¨ï¼ˆè‡ªåŠ¨æ ¼å¼è½¬æ¢ï¼‰
â”‚   â””â”€â”€ helper.py                  # é€šç”¨å·¥å…·å‡½æ•°ï¼ˆS3 ä¸Šä¼ ã€æŠ¥å‘Šä¿å­˜ç­‰ï¼‰
â”œâ”€â”€ *_spend_report.py              # æ¶ˆè€—æŠ¥å‘Š Notebooks
â”œâ”€â”€ *_income_report.py             # æ”¶å…¥æŠ¥å‘Š Notebooks
â”œâ”€â”€ *_audience.py                  # å—ä¼—ä¸Šä¼  Notebooks
â””â”€â”€ data_output/                   # æœ¬åœ°æ•°æ®è¾“å‡ºç›®å½•ï¼ˆstaging æ¨¡å¼ï¼‰
```

---

## ğŸ”§ ç¯å¢ƒé…ç½®

### ç¯å¢ƒæ¨¡å¼

é¡¹ç›®æ”¯æŒä¸¤ç§ç¯å¢ƒæ¨¡å¼ï¼š

| æ¨¡å¼ | è¯´æ˜ | S3 é…ç½® | æœ¬åœ°æ–‡ä»¶ |
|------|------|---------|----------|
| `staging` | æµ‹è¯•æ¨¡å¼ | ä¸Šä¼ åˆ° staging bucket | ä¿å­˜ 5MB é¢„è§ˆåˆ°æœ¬åœ° |
| `prod` | ç”Ÿäº§æ¨¡å¼ | ä¸Šä¼ åˆ° prod bucket | ä¸ä¿å­˜æœ¬åœ°æ–‡ä»¶ |

### è®¾ç½®ç¯å¢ƒæ¨¡å¼

#### æ–¹å¼ä¸€ï¼šä¿®æ”¹ `config_manager.py`

ç¼–è¾‘ `utils/config_manager.py` æ–‡ä»¶é¡¶éƒ¨çš„é…ç½®ï¼š

```python
# ===== é›†ä¸­é…ç½®åŒºåŸŸ =====
DEFAULT_ENV_MODE = 'staging'  # ä¿®æ”¹è¿™é‡Œï¼š'staging' æˆ– 'prod'
# ========================
```

#### æ–¹å¼äºŒï¼šè®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆDatabricks æ¨èï¼‰

```bash
# åœ¨ Databricks Cluster çš„ç¯å¢ƒå˜é‡ä¸­è®¾ç½®
ENV_MODE=prod
```

---

## ğŸ” é…ç½®ç®¡ç†

### é…ç½®ä¼˜å…ˆçº§

é…ç½®åŠ è½½ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š

1. **Databricks Secrets**ï¼ˆæ ¹æ®ç¯å¢ƒè‡ªåŠ¨é€‰æ‹© scopeï¼‰âœ… æ¨è
   - staging: `dcs-staging-secret`
   - prod: `dcs-prod-secret`
2. **ç¯å¢ƒå˜é‡**ï¼ˆCI/CD åœºæ™¯ï¼‰
3. **æœ¬åœ°æ–‡ä»¶ `config/variables.json`**ï¼ˆæœ¬åœ°å¼€å‘ fallbackï¼‰

### S3 è·¯å¾„è§„åˆ™

S3 è·¯å¾„ç”±ä»£ç å†…ç½®é€»è¾‘ç”Ÿæˆï¼Œ**ä¸ä¾èµ–é…ç½®æ–‡ä»¶**ï¼š

```
# staging ç¯å¢ƒ
reports_staging/{ad_type}/{ad_network}/{date}/

# prod ç¯å¢ƒ
reports/{ad_type}/{ad_network}/{date}/
```

ä¾‹å¦‚ï¼š`reports_staging/spend/aarki/2024-01-15/`

### é…ç½®æ ¼å¼

#### Databricks Secretsï¼ˆæ¨èï¼‰

æ•æ„Ÿé…ç½®å­˜å‚¨åœ¨ Databricks Secret Scope ä¸­ï¼Œæ ¹æ®ç¯å¢ƒè‡ªåŠ¨é€‰æ‹©ï¼š

| ç¯å¢ƒ | Secret Scope |
|------|--------------|
| staging | `dcs-staging-secret` |
| prod | `dcs-prod-secret` |

```bash
# æŸ¥çœ‹å·²æœ‰ secrets
databricks secrets list --scope dcs-staging-secret  # staging
databricks secrets list --scope dcs-prod-secret     # prod

# æ·»åŠ æ–° Secretï¼ˆJSON æ ¼å¼ï¼‰
databricks secrets put --scope dcs-staging-secret --key secret_new_config
```

#### ç¯å¢ƒå˜é‡ï¼ˆå¤‡ç”¨ï¼‰

ç¯å¢ƒå˜é‡åéœ€å¤§å†™ï¼Œæ ¼å¼ä¸º `SECRET_{CONFIG_NAME}`ï¼š

```bash
# S3 é…ç½®
export SECRET_AWS_S3_PROD='{"aws_key":"xxx","aws_secret":"xxx","bucket":"prod-bucket"}'
export SECRET_AWS_S3_STAGING='{"aws_key":"xxx","aws_secret":"xxx","bucket":"staging-bucket"}'

# é£ä¹¦é€šçŸ¥
export SECRET_ENV='{"feishu_botid":"xxx"}'

# å„æ¸ é“é…ç½®
export SECRET_APPSFLYER_SPEND='{"token":"xxx"}'
export SECRET_APPLE_SEARCH='{"client_id":"xxx","client_secret":"xxx","org_ids":[...]}'
```

#### æœ¬åœ°é…ç½®æ–‡ä»¶ï¼ˆæœ¬åœ°å¼€å‘ fallbackï¼‰

åˆ›å»º `config/variables.json`ï¼ˆ**æ³¨æ„ï¼šä¸è¦æäº¤åˆ° Git**ï¼‰ï¼š

```json
{
  "secret_aws_s3_prod": {
    "aws_key": "YOUR_AWS_KEY",
    "aws_secret": "YOUR_AWS_SECRET",
    "bucket": "your-prod-bucket"
  },
  "secret_aws_s3_staging": {
    "aws_key": "YOUR_AWS_KEY",
    "aws_secret": "YOUR_AWS_SECRET",
    "bucket": "your-staging-bucket"
  },
  "secret_env": {
    "feishu_botid": "YOUR_FEISHU_BOT_ID"
  }
}
```

---

## â˜ï¸ Databricks éƒ¨ç½²

### 1. ä¸Šä¼ ä»£ç 

å°†é¡¹ç›®æ–‡ä»¶ä¸Šä¼ åˆ° Databricks Workspaceï¼š

```
/Workspace/Repos/Shared/mkt-dcs-staging/
â”œâ”€â”€ utils/
â”œâ”€â”€ config/
â”œâ”€â”€ *_spend_report.py
â””â”€â”€ ...
```

### 2. é…ç½® Secrets

Secrets æ ¹æ®ç¯å¢ƒå­˜å‚¨åœ¨ä¸åŒçš„ scope ä¸­ï¼š
- staging: `dcs-staging-secret`
- prod: `dcs-prod-secret`

å¦‚éœ€æ·»åŠ æ–°é…ç½®ï¼š
```bash
# staging ç¯å¢ƒ
databricks secrets put --scope dcs-staging-secret --key secret_new_config

# prod ç¯å¢ƒ
databricks secrets put --scope dcs-prod-secret --key secret_new_config
```

### 3. åˆ›å»º Job

åœ¨ Databricks ä¸­åˆ›å»º Jobï¼š

- **Task**: é€‰æ‹©å¯¹åº”çš„ Notebook
- **Cluster**: é€‰æ‹©æˆ–åˆ›å»ºè®¡ç®—é›†ç¾¤
- **Parameters**: 
  - `ds`: æ‰§è¡Œæ—¥æœŸï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºæ˜¨å¤©ï¼‰
- **Schedule**: è®¾ç½®è°ƒåº¦æ—¶é—´

### 4. ç¯å¢ƒå˜é‡

åœ¨ Cluster é…ç½®ä¸­æ·»åŠ ç¯å¢ƒå˜é‡ï¼š

```
ENV_MODE=prod
```

---

## ğŸ“‹ Notebook åˆ—è¡¨

### æ¶ˆè€—æŠ¥å‘Š (Spend Report)

| Notebook | æ¸ é“ | æ•°æ®æ ¼å¼ | è¯´æ˜ |
|----------|------|----------|------|
| `aarki_spend_report.py` | Aarki | CSV | â­ æœ€ç®€æ¨¡æ¿ |
| `apple_search_spend_report.py` | Apple Search Ads | JSON | åµŒå¥—æ•°æ®ç»“æ„ |
| `applovin_asset_spend_report.py` | AppLovin | CSV | å¤šè´¦å· |

### æ”¶å…¥æŠ¥å‘Š (Income/Revenue Report)

| Notebook | æ¸ é“ | æ•°æ®æ ¼å¼ | è¯´æ˜ |
|----------|------|----------|------|
| `applovin_income_report.py` | AppLovin | APIå“åº” | `{"code":200,"results":[...]}` |
| `applovin_max_revenue_report.py` | AppLovin MAX | APIå“åº” | åŒä¸Š |
| `applovin_max_ad_revenue_report.py` | AppLovin MAX | APIå“åº” | å¹¿å‘Šæ”¶å…¥ |

### é…ç½®æŠ¥å‘Š (Mediation Config)

| Notebook | æ¸ é“ | æ•°æ®æ ¼å¼ | è¯´æ˜ |
|----------|------|----------|------|
| `applovin_max_report.py` | AppLovin MAX | JSON | ğŸ”§ éœ€å±•å¼€ `ad_network_settings` |

### IAP æŠ¥å‘Š

| Notebook | æ¸ é“ | æ•°æ®æ ¼å¼ | è¯´æ˜ |
|----------|------|----------|------|
| `amazon_iap_report.py` | Amazon | CSV/ZIP | æŒ‰æœˆè·å–ï¼Œéœ€è§£å‹ |

---

## ğŸ“– å¼€å‘è§„èŒƒ

è¯·å‚é˜… [NOTEBOOK_GUIDELINES.md](./NOTEBOOK_GUIDELINES.md) äº†è§£ï¼š

- Notebook ç»“æ„è§„èŒƒï¼ˆ5 ä¸ªæ ‡å‡†éƒ¨åˆ†ï¼‰
- å¤±è´¥å›è°ƒæœºåˆ¶
- å‘½åè§„èŒƒ
- ä»£ç é£æ ¼
- æ—¥å¿—è¾“å‡ºè§„èŒƒ

---

## ğŸ” è°ƒè¯•æŠ€å·§

### æ£€æŸ¥é…ç½®åŠ è½½

```python
# åœ¨ Notebook ä¸­è¿è¡Œ
from utils.config_manager import get_env_mode, get_s3_config

print(f"Environment Mode: {get_env_mode()}")
print(f"S3 Config: {get_s3_config()}")
```

### æŸ¥çœ‹åŸå§‹ API å“åº”ï¼ˆstaging æ¨¡å¼ï¼‰

åœ¨ staging æ¨¡å¼ä¸‹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä¿å­˜åŸå§‹å“åº”çš„å‰ 3MBï¼š

```
data_output/raw_download/{ad_type}/{ad_network}/{date}/{filename}.raw
```

### æµ‹è¯•æ•°æ®æ ¼å¼è§£æ

```python
from utils.data_parser import detect_format, convert_to_jsonl, DataFormat

# æµ‹è¯•æ ¼å¼æ£€æµ‹
sample = '{"code":200,"results":[{"day":"2025-12-09","revenue":100}]}'
fmt = detect_format(sample)
print(f"Detected format: {fmt.value}")  # è¾“å‡º: api_response

# æµ‹è¯•è½¬æ¢
jsonl, count, _ = convert_to_jsonl(sample)
print(f"Converted {count} rows:\n{jsonl}")
# è¾“å‡º: {"day":"2025-12-09","revenue":100}
```

### æµ‹è¯• AppLovin MAX é…ç½®å±•å¼€

```python
from utils.data_parser import expand_applovin_max_ad_unit

ad_unit = {
    "id": "xxx",
    "name": "Test",
    "platform": "ios",
    "ad_network_settings": {
        "UNITY_BIDDING": {"ad_network_ad_unit_id": "unity_123"},
        "ADMOB_BIDDING": {"ad_network_ad_unit_id": "admob_456"}
    }
}

records = expand_applovin_max_ad_unit(ad_unit)
print(f"Expanded to {len(records)} records")
for r in records:
    print(r)
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **è¿è¡Œç¯å¢ƒ**ï¼šæ‰€æœ‰ Notebook å¿…é¡»åœ¨ Databricks é›†ç¾¤ä¸Šè¿è¡Œï¼ŒSQL æŸ¥è¯¢ä½¿ç”¨ `spark.sql()` æ‰§è¡Œ
2. **æ•æ„Ÿä¿¡æ¯**ï¼š`config/variables.json` åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œç¡®ä¿å·²æ·»åŠ åˆ° `.gitignore`
3. **ç¯å¢ƒåˆ‡æ¢**ï¼šåˆ‡æ¢ç¯å¢ƒå‰ç¡®è®¤ S3 bucket é…ç½®æ­£ç¡®ï¼Œé¿å…æ•°æ®å†™å…¥é”™è¯¯ä½ç½®
4. **å¤§æ–‡ä»¶å¤„ç†**ï¼šå¯¹äºå¤§æ–‡ä»¶ï¼Œä½¿ç”¨æµå¼å¤„ç†é¿å…å†…å­˜æº¢å‡º
5. **å¤±è´¥é€šçŸ¥**ï¼šç”Ÿäº§ç¯å¢ƒç¡®ä¿é£ä¹¦ Bot é…ç½®æ­£ç¡®ï¼Œä»¥ä¾¿åŠæ—¶æ”¶åˆ°å¤±è´¥é€šçŸ¥

---

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚
