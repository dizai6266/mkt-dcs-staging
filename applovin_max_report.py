# Databricks notebook source
# MAGIC %md
# MAGIC # AppLovin MAX Report
# MAGIC
# MAGIC è¯¥ Notebook ä» AppLovin MAX API è·å–å¹¿å‘Šå•å…ƒé…ç½®æ•°æ®ã€‚

# COMMAND ----------

# MAGIC %pip install httpx

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. Setup & Imports

# COMMAND ----------

import requests
from datetime import datetime, timedelta
import sys
import os
import pandas as pd

# åŠ¨æ€æ·»åŠ å½“å‰ç›®å½•åˆ° sys.path ä»¥åŠ è½½ utils
current_dir = os.getcwd()
if current_dir not in sys.path:
    sys.path.append(current_dir)

from utils import helper
from utils.config_manager import get_env_mode, setup_feishu_notify
from utils.data_parser import convert_applovin_max_config
import importlib
importlib.reload(helper)

# è®¾ç½® feishu-notifyï¼ˆè·¯å¾„å·²åœ¨ config_manager ä¸­é…ç½®ï¼‰
Notifier = setup_feishu_notify()

print(f"ğŸ”§ Environment Mode: {get_env_mode()}")
print(f"âœ… Environment Setup Complete. Current Dir: {os.getcwd()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Configuration

# COMMAND ----------

# --- [é…ç½®å‚æ•°] ---
_AD_NETWORK = 'max'
_AD_TYPE = 'mediation_config'
_DATE_RANGE = 7

# è·å– Widget å‚æ•°
try:
    dbutils.widgets.text("ds", "", "Execution Date (YYYY-MM-DD)")
    ds_param = dbutils.widgets.get("ds")
except:
    ds_param = ""

if not ds_param:
    ds_param = (datetime.utcnow() - timedelta(days=1)).strftime('%Y-%m-%d')

print(f"ğŸ“… Execution Date: {ds_param}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. Task Logic

# COMMAND ----------

def get_ad_unit_ids(management_key: str):
    """è·å–æ‰€æœ‰å¹¿å‘Šå•å…ƒ ID"""
    url = 'https://o.applovin.com/mediation/v1/ad_units'
    headers = {'Api-Key': management_key}

    response = requests.get(url, headers=headers, timeout=300)
    if response.status_code != 200:
        raise RuntimeError(f'Failed to fetch ad units: {response.status_code} {response.text[:200]}')
    
    results = [item['id'] for item in response.json()]
    return results


def fetch_max_report_task(ds: str):
    """
    è·å– AppLovin MAX é…ç½®æŠ¥å‘Š
    
    Args:
        ds: æ‰§è¡Œæ—¥æœŸ (YYYY-MM-DD)
    """
    try:
        cfg = helper.get_cfg('applovin')
    except Exception as e:
        print(f"âŒ Failed to load config: {e}")
        raise

    management_key = cfg.get('management_key')
    if not management_key:
        print("âš ï¸ No management_key found in config.")
        return

    end_dt = datetime.strptime(ds, '%Y-%m-%d')
    end_ds = ds
    start_dt = end_dt + timedelta(days=-(_DATE_RANGE))
    start_ds = start_dt.strftime('%Y-%m-%d')

    print(f"ğŸ“† Date Range: {start_ds} to {end_ds}")

    # è·å–æ‰€æœ‰å¹¿å‘Šå•å…ƒ ID
    print("ğŸ“¡ Fetching ad unit IDs...")
    ad_units = get_ad_unit_ids(management_key)
    print(f"ğŸ“‹ Found {len(ad_units)} ad unit(s)")

    # æ”¶é›†æ‰€æœ‰å¹¿å‘Šå•å…ƒçš„æ•°æ®
    all_records = []
    
    for ad_unit in ad_units:
        print(f"   ğŸ“¦ Processing ad unit: {ad_unit}")
        
        try:
            url = f'https://o.applovin.com/mediation/v1/ad_unit/{ad_unit}'
            headers = {'Api-Key': management_key}
            params = {'fields': 'ad_network_settings'}
            
            response = requests.get(url, headers=headers, params=params, timeout=300)
            
            if response.status_code != 200:
                print(f"      âš ï¸ Failed to fetch ad unit {ad_unit}: {response.status_code}")
                continue
            
            # ä½¿ç”¨ä¸“ç”¨è½¬æ¢å™¨å±•å¼€ ad_network_settings
            jsonl_content, row_count = convert_applovin_max_config(response.text)
            
            if jsonl_content:
                # æ”¶é›†è®°å½•
                for line in jsonl_content.split('\n'):
                    if line.strip():
                        all_records.append(line)
                print(f"      âœ… Extracted {row_count} network records")
            else:
                print(f"      âš ï¸ No data extracted for ad unit {ad_unit}")
                
        except Exception as e:
            print(f"      âŒ Error processing ad unit {ad_unit}: {e}")
            continue

    print(f"\nğŸ“Š Total records collected: {len(all_records)}")
    
    # åˆå¹¶æ‰€æœ‰è®°å½•å¹¶ä¿å­˜
    if all_records:
        combined_content = '\n'.join(all_records)
        
        helper.save_report(
            ad_network=_AD_NETWORK,
            ad_type=_AD_TYPE,
            report_content=combined_content,
            exc_ds=ds,
            start_ds=start_ds,
            end_ds=end_ds,
            data_format='jsonl'  # å·²ç»æ˜¯ JSONL æ ¼å¼
        )
        print(f"âœ… Saved {_AD_NETWORK} report for {start_ds} to {end_ds}")
    else:
        print(f"âš ï¸ No data to save for {_AD_NETWORK}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. Execution

# COMMAND ----------

print(f"ğŸš€ Starting Job for {_AD_NETWORK}")

try:
    fetch_max_report_task(ds_param)
    print("\nâœ… Job Finished Successfully")

except Exception as e:
    print(f"\nâŒ Job Failed: {e}")
    # on_failure_callback: å¤±è´¥æ—¶å‘é€é£ä¹¦é€šçŸ¥
    helper.failure_callback(str(e), f"{_AD_NETWORK}_report")
    raise e

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. Data Validation

# COMMAND ----------

env_mode = get_env_mode()
print(f"\nğŸ” Data Validation (ENV_MODE={env_mode})")

helper.validate_and_preview_data(_AD_TYPE, _AD_NETWORK)
