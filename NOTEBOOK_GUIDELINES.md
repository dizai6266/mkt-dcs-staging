# Databricks Notebook å¼€å‘è§„èŒƒ (NOTEBOOK_GUIDELINES.md)

> æœ¬è§„èŒƒé€‚ç”¨äºä» Airflow DAG è¿ç§»åˆ° Databricks Notebook çš„æ•°æ®æŠ¥å‘Šä»»åŠ¡ã€‚éµå¾ªæœ¬è§„èŒƒå¯ç¡®ä¿ä»£ç ä¸€è‡´æ€§ï¼Œä¾¿äºç»´æŠ¤å’Œ AI è¾…åŠ©å¼€å‘ã€‚

---

## ç›®å½•ç»“æ„

```
mkt-dcs-staging/
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ helper.py           # æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆä¸Šä¼ ã€ä¿å­˜ã€é€šçŸ¥ç­‰ï¼‰
â”‚   â””â”€â”€ config_manager.py   # é…ç½®ç®¡ç†ï¼ˆç¯å¢ƒã€å¯†é’¥ã€S3è·¯å¾„ï¼‰
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ iap/
â”‚   â”‚   â””â”€â”€ amazon_iap_report.py
â”‚   â”œâ”€â”€ spend/
â”‚   â”‚   â”œâ”€â”€ applovin_asset_spend_report.py
â”‚   â”‚   â””â”€â”€ apple_search_spend_report.py
â”‚   â””â”€â”€ income/
â”‚       â””â”€â”€ ...
â””â”€â”€ data_output/            # æœ¬åœ°è¾“å‡ºç›®å½•ï¼ˆstaging/dev æ¨¡å¼ï¼‰
```

---

## Notebook æ ‡å‡†ç»“æ„ï¼ˆ6 ä¸ªéƒ¨åˆ†ï¼‰

æ¯ä¸ª Notebook å¿…é¡»åŒ…å«ä»¥ä¸‹ 6 ä¸ªéƒ¨åˆ†ï¼ŒæŒ‰é¡ºåºæ’åˆ—ï¼š

### Part 1: æ ‡é¢˜ä¸è¯´æ˜

```python
# Databricks notebook source
# MAGIC %md
# MAGIC # {å¹¿å‘Šç½‘ç»œ} {æŠ¥å‘Šç±»å‹} Report
# MAGIC
# MAGIC ç®€è¦è¯´æ˜è¯¥ Notebook çš„åŠŸèƒ½ã€‚
```

**ç¤ºä¾‹** [1]ï¼š
```python
# MAGIC # Amazon IAP Report
# MAGIC
# MAGIC è¯¥ Notebook ä» Amazon API è·å– IAP é”€å”®æŠ¥å‘Šæ•°æ®ã€‚
```

---

### Part 2: Setup & Imports

```python
# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. Setup & Imports

# COMMAND ----------

import gzip
import io
import json
import os
import shutil
import zipfile
from datetime import datetime, timedelta
import sys

import pandas as pd
import requests

# åŠ¨æ€æ·»åŠ å½“å‰ç›®å½•åˆ° sys.path
current_dir = os.getcwd()
if current_dir not in sys.path:
    sys.path.append(current_dir)

from utils import helper
from utils.config_manager import get_env_mode, setup_feishu_notify
import importlib
importlib.reload(helper)

# è®¾ç½®é£ä¹¦é€šçŸ¥
Notifier = setup_feishu_notify()

print(f"ğŸ”§ Environment Mode: {get_env_mode()}")
print(f"âœ… Environment Setup Complete. Current Dir: {os.getcwd()}")
```

---

### Part 3: Configuration

```python
# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Configuration

# COMMAND ----------

# --- [é…ç½®å‚æ•°] ---
_AD_NETWORK = '{å¹¿å‘Šç½‘ç»œå}'    # ä¾‹å¦‚: 'amazon', 'applovin', 'apple_search'
_AD_TYPE = '{æŠ¥å‘Šç±»å‹}'          # å¯é€‰å€¼: 'iap', 'spend', 'income', 'attribution'

# --- [æ—¥æœŸå‚æ•°] ---
try:
    dbutils.widgets.text("ds", "", "Date (YYYY-MM-DD)")
    ds_param = dbutils.widgets.get("ds")
except:
    ds_param = ""

if not ds_param:
    ds_param = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')

print(f"ğŸ“… Execution Date: {ds_param}")
```

**é…ç½®å‚æ•°è¯´æ˜**ï¼š

| å˜é‡ | è¯´æ˜ | ç¤ºä¾‹å€¼ |
|------|------|--------|
| `_AD_NETWORK` | å¹¿å‘Šç½‘ç»œæ ‡è¯†ï¼ˆå°å†™ï¼‰ | `'amazon'`, `'applovin'`, `'apple_search'` |
| `_AD_TYPE` | æŠ¥å‘Šç±»å‹ | `'iap'`, `'spend'`, `'income'`, `'attribution'` |
| `ds_param` | æ‰§è¡Œæ—¥æœŸ | `'2025-12-09'` |

---

### Part 4: Core Functions

```python
# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. Core Functions

# COMMAND ----------

# åœ¨æ­¤å®šä¹‰æ‰€æœ‰ä¸šåŠ¡é€»è¾‘å‡½æ•°
```

#### 4.1 æ ¸å¿ƒå‡½æ•°å‘½åè§„èŒƒ

| å‡½æ•°ç±»å‹ | å‘½åæ ¼å¼ | ç¤ºä¾‹ |
|----------|----------|------|
| ä¸»ä»»åŠ¡å‡½æ•° | `fetch_{type}_report_task(ds)` | `fetch_iap_report_task(ds)` |
| æ•°æ®å¤„ç†å‡½æ•° | `_process_and_upload(...)` | `_process_and_upload(file_path, year, month, ds, client_index)` |
| API è°ƒç”¨å‡½æ•° | `_get_{resource}(...)` | `_get_access_token(...)`, `_get_sale_report_url(...)` |
| è¾…åŠ©å‡½æ•° | `_helper_name(...)` | `_get_month_last_day(year, month)` |

#### 4.2 ä¸»ä»»åŠ¡å‡½æ•°æ¨¡æ¿

```python
def fetch_{type}_report_task(ds: str):
    """
    è·å– {AD_NETWORK} {TYPE} æŠ¥å‘Š
    
    Args:
        ds: æ‰§è¡Œæ—¥æœŸ (YYYY-MM-DD)
    """
    print(f"ğŸ“Š Fetching {_AD_NETWORK} report for {ds}")
    
    # 1. è·å–é…ç½®
    cfg = helper.get_cfg('{config_name}')
    
    # 2. éå†è´¦å·/å®¢æˆ·ç«¯
    for index, item in enumerate(cfg.get('{key}'), start=1):
        print(f"\n   ğŸ“± Processing item {index}...")
        
        # 3. è·å–æ•°æ®
        # ...
        
        # 4. å¤„ç†å¹¶ä¿å­˜
        helper.save_report(
            ad_network=_AD_NETWORK,
            ad_type=_AD_TYPE,
            report=report_data,      # æ”¯æŒ CSV/JSON/JSONL æ ¼å¼ï¼Œè‡ªåŠ¨è½¬æ¢
            exc_ds=ds,
            start_ds=start_date,
            end_ds=end_date,
            custom=index             # å¯é€‰ï¼šç”¨äºåŒºåˆ†å¤šè´¦å·
        )
        
        print(f"   âœ… Processed item {index}")
    
    print(f"\nâœ… Saved {_AD_NETWORK} report for {ds}")
```

#### 4.3 helper.save_report() å‚æ•°è¯´æ˜

```python
helper.save_report(
    ad_network: str,      # å¿…å¡«ï¼šå¹¿å‘Šç½‘ç»œå
    ad_type: str,         # å¿…å¡«ï¼šæŠ¥å‘Šç±»å‹
    report: str,          # å¿…å¡«ï¼šæŠ¥å‘Šæ•°æ®ï¼ˆæ”¯æŒ CSV/JSON/JSONLï¼Œè‡ªåŠ¨æ£€æµ‹è½¬æ¢ï¼‰
    exc_ds: str,          # å¿…å¡«ï¼šæ‰§è¡Œæ—¥æœŸ
    start_ds: str,        # å¯é€‰ï¼šæ•°æ®å¼€å§‹æ—¥æœŸ
    end_ds: str,          # å¯é€‰ï¼šæ•°æ®ç»“æŸæ—¥æœŸ
    report_ds: str,       # å¯é€‰ï¼šæŠ¥å‘Šæ—¥æœŸï¼ˆä¸ start_ds/end_ds äºŒé€‰ä¸€ï¼‰
    custom: any,          # å¯é€‰ï¼šè‡ªå®šä¹‰æ ‡è¯†ï¼ˆç”¨äºæ–‡ä»¶ååŒºåˆ†å¤šè´¦å·ï¼‰
    data_format: str      # å¯é€‰ï¼šå¼ºåˆ¶æŒ‡å®šæ ¼å¼ ('csv'/'jsonl'/'json_array')
)
```

**ç”Ÿæˆçš„æ–‡ä»¶åè§„åˆ™**ï¼š

| å‚æ•°ç»„åˆ | æ–‡ä»¶åæ ¼å¼ | ç¤ºä¾‹ |
|----------|------------|------|
| `custom` + `start_ds` + `end_ds` | `{network}_{custom}_{start}_to_{end}` | `applovin_1_2025-12-02_to_2025-12-08` |
| `start_ds` + `end_ds` | `{network}_{start}_to_{end}` | `amazon_2025-12-01_to_2025-12-31` |
| `report_ds` | `{network}_{report_ds}` | `facebook_2025-12-09` |

**æ”¯æŒçš„æ•°æ®æ ¼å¼**ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰ï¼š

| æ ¼å¼ | è¯†åˆ«ç‰¹å¾ | å¤„ç†æ–¹å¼ |
|------|----------|----------|
| JSONL | æ¯è¡Œä»¥ `{` å¼€å¤´ `}` ç»“å°¾ | ç›´æ¥éªŒè¯ï¼Œä¸è½¬æ¢ |
| JSON Array | ä»¥ `[` å¼€å¤´ | è½¬æ¢ä¸º JSONL |
| JSON Object | ä»¥ `{` å¼€å¤´ï¼ˆå•è¡Œï¼‰ | è½¬æ¢ä¸ºå•è¡Œ JSONL |
| CSV | å…¶ä»–æƒ…å†µ | è½¬æ¢ä¸º JSONL |

---

### Part 5: Execution

```python
# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. Execution

# COMMAND ----------

print(f"ğŸš€ Starting Job for {_AD_NETWORK}")

try:
    fetch_{type}_report_task(ds_param)
    print("\nâœ… Job Finished Successfully")

except Exception as e:
    print(f"\nâŒ Job Failed: {e}")
    helper.failure_callback(str(e), f"{_AD_NETWORK}_{_AD_TYPE}_report")
    raise e  # å¿…é¡»é‡æ–°æŠ›å‡ºï¼Œä¿æŒ Job å¤±è´¥çŠ¶æ€
```

---

### Part 6: Data Validation

```python
# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. Data Validation

# COMMAND ----------

env_mode = get_env_mode()
print(f"\nğŸ” Data Validation (ENV_MODE={env_mode})")

if env_mode != 'staging':
    print("âš ï¸ é staging æ¨¡å¼ï¼Œè·³è¿‡æœ¬åœ° previewã€‚")
else:
    try:
        base_root = getattr(helper, "_DATA_BASE_PATH", None) or os.path.join(os.getcwd(), "data_output")
        preview_root = os.path.join(base_root, _AD_TYPE, _AD_NETWORK)
        print(f"ğŸ” Scanning preview files under: {preview_root}")
        
        if not os.path.exists(preview_root):
            print(f"âš ï¸ Preview directory does not exist: {preview_root}")
        else:
            preview_files = []
            for root, dirs, files in os.walk(preview_root):
                for name in files:
                    if name.endswith('.preview'):
                        preview_files.append(os.path.join(root, name))
            
            print(f"âœ… Found {len(preview_files)} preview file(s)")
            
            for sample_file in preview_files:
                print(f"\n   Previewing: {sample_file}")
                try:
                    df = pd.read_json(sample_file, lines=True)
                    try:
                        display(df.head(5))
                    except NameError:
                        print(df.head(5).to_string())
                    print(f"   Total rows: {len(df)}\n")
                except Exception as e:
                    print(f"   âŒ Failed to read preview file: {e}")
    except Exception as e:
        print(f"âŒ Preview scan error: {e}")
```

---

## ç¯å¢ƒæ¨¡å¼è¯´æ˜

| æ¨¡å¼ | æœ¬åœ°æ–‡ä»¶ | S3 ä¸Šä¼  | ç”¨é€” |
|------|----------|---------|------|
| `dev` | å®Œæ•´æ•°æ® (`.jsonl`) | âŒ | æœ¬åœ°å¼€å‘è°ƒè¯• |
| `staging` | 5MB é¢„è§ˆ (`.preview`) | âœ… (`reports_staging/`) | æµ‹è¯•éªŒè¯ |
| `prod` | âŒ | âœ… (`reports/`) | ç”Ÿäº§ç¯å¢ƒ |

---

## å¸¸è§è¿ç§»æ¨¡å¼

### æ¨¡å¼ Aï¼šå•è´¦å· + å•æ—¥æœŸèŒƒå›´

**é€‚ç”¨åœºæ™¯**ï¼šAppLovin Asset, Facebook ç­‰

```python
def fetch_spend_report_task(ds: str):
    cfg = helper.get_cfg('applovin')
    
    for item in cfg.get('spend'):
        account_index = item.get('index')
        
        # è·å–æŠ¥å‘Š...
        
        helper.save_report(
            ad_network=_AD_NETWORK,
            ad_type=_AD_TYPE,
            report=report_str,
            exc_ds=ds,
            start_ds=start_ds,
            end_ds=end_ds,
            custom=account_index
        )
```

### æ¨¡å¼ Bï¼šå¤šè´¦å· + å¤šæœˆä»½

**é€‚ç”¨åœºæ™¯**ï¼šAmazon IAPï¼ˆæŒ‰æœˆè·å–ï¼‰

```python
def fetch_iap_report_task(ds: str):
    cfg = helper.get_cfg('amazon')
    
    for client_index, client in enumerate(cfg.get('iap'), start=1):
        # è·å–å½“æœˆå’Œä¸Šæœˆæ•°æ®
        for t in [curr_dt, last_month_dt]:
            year, month = t.year, t.month
            last_day = _get_month_last_day(year, month)
            
            # è·å–å¹¶å¤„ç†æŠ¥å‘Š...
            
            helper.save_report(
                ad_network=_AD_NETWORK,
                ad_type=_AD_TYPE,
                report=report_data,
                exc_ds=ds,
                start_ds=f'{year}-{month:02d}-01',
                end_ds=f'{year}-{month:02d}-{last_day:02d}',
                custom=client_index
            )
```

### æ¨¡å¼ Cï¼šåµŒå¥—æ•°æ®ç»“æ„

**é€‚ç”¨åœºæ™¯**ï¼šApple Search Adsï¼ˆCampaign â†’ Keywordsï¼‰

```python
def fetch_spend_report_task(ds: str):
    campaign_infos = []
    
    for org in cfg.get('spend'):
        # è·å– campaign åˆ—è¡¨
        campaigns = _get_campaigns(org)
        
        for campaign in campaigns:
            # è·å– campaign ä¸‹çš„è¯¦ç»†æ•°æ®
            report = _get_campaign_report(campaign)
            detail_data = _parse_detail_data(report, campaign_info=campaign)
            campaign_infos.extend(detail_data)
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®åä¿å­˜
    helper.save_report(
        ad_network=_AD_NETWORK,
        ad_type=_AD_TYPE,
        report=json.dumps(campaign_infos),
        exc_ds=ds,
        report_ds=ds
    )
```

---

## è¾…åŠ©å‡½æ•°åº“

### è·å–æœˆä»½æœ€åä¸€å¤©

```python
def _get_month_last_day(year: int, month: int) -> int:
    """è·å–æŒ‡å®šæœˆä»½çš„æœ€åä¸€å¤©"""
    if month == 12:
        next_month_first = datetime(year + 1, 1, 1)
    else:
        next_month_first = datetime(year, month + 1, 1)
    return (next_month_first - timedelta(days=1)).day
```

### CSV æ·»åŠ é¢å¤–åˆ—

```python
def _add_columns_to_csv(csv_str: str, extra_columns: dict) -> str:
    """ç»™ CSV æ•°æ®æ·»åŠ é¢å¤–åˆ—"""
    lines = csv_str.strip().split('\n')
    if not lines:
        return csv_str
    
    # æ·»åŠ  header
    extra_keys = ','.join(extra_columns.keys())
    header = f"{lines[0]},{extra_keys}"
    
    # æ·»åŠ æ•°æ®
    extra_values = ','.join(str(v) for v in extra_columns.values())
    modified_lines = [header]
    for line in lines[1:]:
        if line.strip():
            modified_lines.append(f"{line},{extra_values}")
    
    return '\n'.join(modified_lines)
```

---

## Checklist

æ–°å¢ Notebook å‰ï¼Œè¯·ç¡®è®¤ä»¥ä¸‹äº‹é¡¹ï¼š

- [ ] è®¾ç½®æ­£ç¡®çš„ `_AD_NETWORK` å’Œ `_AD_TYPE`
- [ ] é…ç½®å·²æ·»åŠ åˆ° Databricks Secrets
- [ ] ä¸»å‡½æ•°å‘½åéµå¾ª `fetch_{type}_report_task(ds)` æ ¼å¼
- [ ] ä½¿ç”¨ `helper.save_report()` ä¿å­˜æ•°æ®
- [ ] åŒ…å« try-except å’Œ `helper.failure_callback()`
- [ ] åŒ…å« Data Validation éƒ¨åˆ†
- [ ] åœ¨ staging ç¯å¢ƒæµ‹è¯•é€šè¿‡
- [ ] Preview æ–‡ä»¶å¯æ­£å¸¸è¯»å–ï¼ˆ`pd.read_json(file, lines=True)`ï¼‰

---

## å¸¸è§é—®é¢˜æ’æŸ¥

| é—®é¢˜ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|----------|----------|
| Preview æ–‡ä»¶è¯»å–å¤±è´¥ | JSON æ ¼å¼é”™è¯¯ | æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹æ®Šå­—ç¬¦ï¼Œä½¿ç”¨ `force_ascii=False` |
| å¤šè´¦å·æ–‡ä»¶è¦†ç›– | æœªä½¿ç”¨ `custom` å‚æ•° | æ·»åŠ  `custom=index` åŒºåˆ†æ–‡ä»¶å |
| S3 ä¸Šä¼ å¤±è´¥ | é…ç½®ç¼ºå¤± | æ£€æŸ¥ Secrets ä¸­çš„ S3 é…ç½® |
| æ•°æ®è¢«æˆªæ–­ | 5MB preview é™åˆ¶ | æ­£å¸¸ç°è±¡ï¼Œå®Œæ•´æ•°æ®åœ¨ S3 |