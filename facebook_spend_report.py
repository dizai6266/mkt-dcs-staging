# Databricks notebook source
# MAGIC %md
# MAGIC # Facebook Spend Report
# MAGIC
# MAGIC è¯¥ Notebook ä» Facebook Marketing API è·å–å¹¿å‘Šæ¶ˆè€—æ•°æ®ã€‚
# MAGIC
# MAGIC - ä½¿ç”¨å¼‚æ­¥ Job è·å– Insights
# MAGIC - å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†
# MAGIC - æ”¯æŒå¤šè´¦æˆ·

# COMMAND ----------

# MAGIC %pip install facebook-business pandas

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. Setup & Imports

# COMMAND ----------

import json
import requests
import pandas as pd
from datetime import datetime, timedelta
from time import sleep
from concurrent.futures import ThreadPoolExecutor, as_completed
import sys
import os

# åŠ¨æ€æ·»åŠ å½“å‰ç›®å½•åˆ° sys.path ä»¥åŠ è½½ utils
current_dir = os.getcwd()
if current_dir not in sys.path:
    sys.path.append(current_dir)

from utils import helper
from utils.config_manager import get_env_mode, setup_feishu_notify
import importlib
importlib.reload(helper)

from facebook_business.adobjects.adaccountuser import AdAccountUser as AdUser
from facebook_business.adobjects.adaccount import AdAccount
from facebook_business.api import FacebookAdsApi

# è®¾ç½® feishu-notify
Notifier = setup_feishu_notify()

print(f"ğŸ”§ Environment Mode: {get_env_mode()}")
print(f"âœ… Environment Setup Complete. Current Dir: {os.getcwd()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Configuration

# COMMAND ----------

# --- [é…ç½®å‚æ•°] ---
_AD_NETWORK = 'facebook'
_AD_TYPE = 'spend'
_DATE_RANGE = 3

# è¯­è¨€æ˜ å°„è¡¨ï¼ˆä¸­æ–‡/è¶Šå—æ–‡ -> è‹±æ–‡ï¼‰
LAN_MAP = {
    # å¤„ç†ä¸­æ–‡è¡¨å¤´
    'æŠ¥å‘Šå¼€å§‹æ—¥æœŸ': 'Reporting Starts', 'æŠ¥å‘Šç»“æŸæ—¥æœŸ': 'Reporting Ends', 
    'å›½å®¶/åœ°åŒº': 'Country', 'è´§å¸': 'Currency',
    'å¸æˆ·ç¼–å·': 'Account ID', 'å¸æˆ·åç§°': 'Account Name', 
    'å¹¿å‘Šç¼–å·': 'Ad ID', 'å¹¿å‘Šåç§°': 'Ad Name', 'å¹¿å‘Šç»„ç¼–å·': 'Ad Set ID', 
    'å¹¿å‘Šç»„åç§°': 'Ad Set Name', 'å¹¿å‘Šç³»åˆ—ç¼–å·': 'Campaign ID', 
    'å¹¿å‘Šç³»åˆ—åç§°': 'Campaign Name', 'åœ°åŒºï¼ˆå¹¿å‘Šç»„è®¾ç½®ï¼‰': 'Location (Ad Set Settings)', 
    'ç§»åŠ¨åº”ç”¨å®‰è£…': 'Mobile App Installs', 'åº”ç”¨å®‰è£…': 'App Installs', 
    'å±•ç¤ºæ¬¡æ•°': 'Impressions', 'ç‚¹å‡»é‡ï¼ˆå…¨éƒ¨ï¼‰': 'Clicks (All)', 
    '"èŠ±è´¹é‡‘é¢ (USD)"': 'Amount Spent (USD)', 'èŠ±è´¹é‡‘é¢ (USD)': 'Amount Spent (USD)', 
    'å¹³å°': 'platform',
    '\"è§†é¢‘æ’­æ”¾è¿›åº¦è¾¾ 25% çš„æ¬¡æ•°\"': 'video plays at 25%"', 
    '\"è§†é¢‘æ’­æ”¾è¿›åº¦è¾¾ 50% çš„æ¬¡æ•°\"': 'video plays at 50%"', 
    '\"è§†é¢‘æ’­æ”¾è¿›åº¦è¾¾ 75% çš„æ¬¡æ•°\"': 'video plays at 75%"', 
    '\"è§†é¢‘æ’­æ”¾è¿›åº¦è¾¾ 95% çš„æ¬¡æ•°\"': 'video plays at 95%"', 
    '\"è§†é¢‘æ’­æ”¾è¿›åº¦è¾¾ 100% çš„æ¬¡æ•°\"': 'video plays at 100%"',
    'è§†é¢‘æ’­æ”¾é‡': 'video plays', 'è§†é¢‘å¹³å‡æ’­æ”¾æ—¶é•¿': 'video average play time',
    # å¤„ç†è¶Šå—æ–‡è¡¨å¤´
    '"Báº¯t Ä‘áº§u bÃ¡o cÃ¡o"': 'Reporting Starts', '"Káº¿t thÃºc bÃ¡o cÃ¡o"': 'Reporting Ends', 
    '"Quá»‘c gia"': 'Country', '"ÄÆ¡n vá»‹ tiá»n tá»‡"': 'Currency',
    '"ID tÃ i khoáº£n"': 'Account ID', '"TÃªn tÃ i khoáº£n"': 'Account Name', 
    '"MÃ£ quáº£ng cÃ¡o"': 'Ad ID', '"TÃªn quáº£ng cÃ¡o"': 'Ad Name', 
    '"ID nhÃ³m quáº£ng cÃ¡o"': 'Ad Set ID', '"TÃªn nhÃ³m quáº£ng cÃ¡o"': 'Ad Set Name', 
    '"ID chiáº¿n dá»‹ch"': 'Campaign ID', '"TÃªn chiáº¿n dá»‹ch"': 'Campaign Name', 
    '"LÆ°á»£t cÃ i Ä‘áº·t á»©ng dá»¥ng di Ä‘á»™ng"': 'Mobile App Installs', 
    '"LÆ°á»£t cÃ i Ä‘áº·t á»©ng dá»¥ng"': 'App Installs', 
    '"LÆ°á»£t hiá»ƒn thá»‹"': 'Impressions', '"Sá»‘ láº§n nháº¥p (Táº¥t cáº£)"': 'Clicks (All)', 
    '"Sá»‘ tiá»n Ä‘Ã£ chi tiÃªu (USD)"': 'Amount Spent (USD)',
}

# è·å– Widget å‚æ•°
try:
    dbutils.widgets.text("ds", "", "Execution Date (YYYY-MM-DD)")
    ds_param = dbutils.widgets.get("ds")
except:
    ds_param = ""

if not ds_param:
    ds_param = (datetime.utcnow() - timedelta(days=1)).strftime('%Y-%m-%d')

print(f"ğŸ“… Execution Date: {ds_param}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. Core Functions

# COMMAND ----------

def _get_insights(account_info, start_ds, ds, cfg):
    """
    è·å–å•ä¸ªè´¦æˆ·çš„ Insights å¼‚æ­¥ä»»åŠ¡
    
    Args:
        account_info: (account, category) å…ƒç»„
        start_ds: å¼€å§‹æ—¥æœŸ
        ds: ç»“æŸæ—¥æœŸ
        cfg: é…ç½®ä¿¡æ¯
        
    Returns:
        (category, report_run_id, account_id, start_ds, ds) æˆ–å¤±è´¥æ—¶ report_run_id=-1
    """
    account, category = account_info[0], account_info[1]
    account_id = account['account_id']
    print(f'   ğŸ“¡ Getting insights for account: {account_id}')
    
    report_info = None
    fields = [
        'account_currency', 'account_id', 'account_name', 'ad_id', 'ad_name', 
        'adset_id', 'adset_name', 'campaign_id', 'campaign_name', 'impressions',
        'clicks', 'spend', 'cpc', 'cpm', 'ctr', 'actions',
        'cost_per_ad_click', 'cost_per_conversion',
    ]
    breakdowns = ['country']
    
    params = {
        'level': 'ad',
        'breakdowns': breakdowns,
        'time_range': {'since': start_ds, 'until': ds},
        'time_increment': 1,
        'fields': fields,
    }
    
    max_retries = 2
    for retry in range(max_retries):
        try:
            async_job = account.get_insights(params=params, is_async=True)
            async_job.api_get()
            
            # ç­‰å¾…å¼‚æ­¥ä»»åŠ¡å®Œæˆ
            max_wait = 24
            wait_count = 0
            while async_job['async_percent_completion'] < 100:
                if async_job['async_status'] not in ['Job Running', 'Job Not Started', 'Job Started']:
                    raise RuntimeError(f"{account_id} failed, status: {async_job['async_status']}")
                wait_count += 1
                if wait_count > max_wait:
                    raise RuntimeError(f"{account_id} timeout, status: {async_job['async_status']}")
                sleep(5)
                async_job.api_get()
            
            sleep(1)
            async_job.api_get()
            report_run_id = async_job['report_run_id']
            report_info = (category, report_run_id, account_id, start_ds, ds)
            print(f'   âœ… Got insights for account: {account_id}')
            break
            
        except Exception as e:
            print(f"   âš ï¸ Retry {retry + 1} for account {account_id}: {e}")
            sleep((retry + 1) * 2.5)
    
    if report_info is None:
        report_info = (category, -1, account_id, start_ds, ds)
    
    return report_info


def _get_insights_wrapper(task_args):
    """å¤šçº¿ç¨‹è°ƒç”¨åŒ…è£…å‡½æ•°"""
    account_info, start_ds, ds, cfg = task_args
    return _get_insights(account_info, start_ds, ds, cfg)


def _fetch_export_report(report_id, category, params, cfg):
    """
    ä¸‹è½½å¯¼å‡ºæŠ¥å‘Š
    
    Args:
        report_id: æŠ¥å‘Šè¿è¡Œ ID
        category: ç±»åˆ«ï¼ˆå¯ä¸º Noneï¼‰
        params: åŒ…å« account, exec_ds, start_ds, ds çš„å­—å…¸
        cfg: é…ç½®ä¿¡æ¯
        
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    account = params.get("account")
    exec_ds = params.get('exec_ds')
    start_ds = params.get("start_ds")
    ds = params.get("ds")
    
    url = 'https://www.facebook.com/ads/ads_insights/export_report/'
    report_params = {
        'report_run_id': report_id,
        'format': 'csv',
        'access_token': cfg.get('market')
    }
    
    for retry in range(3):
        try:
            resp = requests.get(url, params=report_params)
            if resp.status_code not in [200, 204]:
                raise RuntimeError(f'Failed to download report: {resp.text}')
            
            report_str = resp.text
            if '"<!doctype html>' in report_str:
                raise RuntimeError(f'{params} fetch report failed, got HTML response')
            
            # æ›¿æ¢è¡¨å¤´è¯­è¨€
            first_line = report_str.split('\n')[0]
            dimensions = first_line.split(',')
            new_dimensions = [LAN_MAP.get(item, item) for item in dimensions]
            new_first_line = ",".join(new_dimensions)
            report_str = report_str.replace(first_line, new_first_line, 1)
            
            # ä¿å­˜æŠ¥å‘Š
            return helper.save_report(
                ad_network=f'{_AD_NETWORK}_{category}' if category else _AD_NETWORK,
                ad_type=_AD_TYPE,
                report=report_str,
                exc_ds=exec_ds,
                start_ds=start_ds,
                end_ds=ds,
                custom=account
            )
            
        except Exception as e:
            print(f"   âš ï¸ Retry {retry + 1} downloading report: {e}")
            sleep(2)
    
    # æ‰€æœ‰é‡è¯•å¤±è´¥
    helper.sql_error_bot(
        title=f'Facebook spend report {account}',
        text=f'Facebook failed get report\n\n {category} {account} {report_id}'
    )
    raise RuntimeError(f'{category} {account} {report_id} Failed to get the report')


def fetch_spend_report_task(ds: str):
    """
    è·å– Facebook Spend æŠ¥å‘Š
    
    Args:
        ds: æ‰§è¡Œæ—¥æœŸ (YYYY-MM-DD)
    """
    print(f"ğŸ“Š Fetching {_AD_NETWORK} spend report for {ds}")
    
    cfg = helper.get_cfg(_AD_NETWORK)
    
    end_dt = datetime.strptime(ds, '%Y-%m-%d')
    start_dt = end_dt + timedelta(days=-_DATE_RANGE)
    start_ds = start_dt.strftime('%Y-%m-%d')
    
    print(f"ğŸ“† Date Range: {start_ds} to {ds}")
    
    # åˆå§‹åŒ– Facebook API
    market = cfg.get('market')
    FacebookAdsApi.init(access_token=market)
    
    # è·å–è´¦æˆ·åˆ—è¡¨
    fields = ['id', 'account_id', 'account_status', 'age', 'amount_spent', 'name', 
              'business', 'business_name', 'disable_reason']
    me = AdUser(fbid='me')
    
    account_list = None
    for retry in range(3):
        try:
            account_list = list(me.get_ad_accounts(fields=fields))
            if account_list:
                break
        except Exception as e:
            print(f'   âš ï¸ Retry {retry + 1} getting ad accounts: {e}')
            sleep(20)
    
    if not account_list:
        raise RuntimeError('Failed to get ad accounts')
    
    # æ·»åŠ é¢å¤–è´¦æˆ·
    for account_id in cfg.get('accounts_not_obtained', []):
        extra_account = AdAccount(account_id)
        extra_account.api_get(fields=fields)
        account_list.append(extra_account)
    
    print(f"   ğŸ“± Found {len(account_list)} account(s)")
    
    # æ„å»ºä»»åŠ¡åˆ—è¡¨
    tasks = []
    split_accounts = cfg.get('market_split_date_accounts', '').strip(',').split(',')
    miss_accounts = cfg.get('market_miss_accounts', '').strip(',').split(',')
    category = None  # æ™®é€š spend report ä¸åˆ† category
    
    for account in account_list:
        if account["account_id"] in miss_accounts:
            continue
        if account["account_status"] != 1:
            continue
        
        is_split_account = False
        for split_info in split_accounts:
            if not split_info:
                continue
            splits = split_info.split('|')
            split_account_id, split_step = splits[0], int(splits[1])
            if account["account_id"] == split_account_id:
                is_split_account = True
                s_dt = start_dt
                while s_dt <= end_dt:
                    c_dt = min(s_dt + timedelta(days=split_step), end_dt)
                    tasks.append(((account, category), s_dt.strftime('%Y-%m-%d'), c_dt.strftime('%Y-%m-%d'), cfg))
                    s_dt = c_dt + timedelta(days=1)
        
        if not is_split_account:
            tasks.append(((account, category), start_ds, ds, cfg))
    
    # ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œæ‰§è¡Œ
    results = []
    max_workers = min(3, len(tasks))
    
    if tasks:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_task = {executor.submit(_get_insights_wrapper, task): task for task in tasks}
            for future in as_completed(future_to_task):
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                except Exception as e:
                    task = future_to_task[future]
                    account_info = task[0]
                    print(f"   âŒ Task failed for account {account_info[0]['account_id']}: {e}")
    
    # å¤„ç†ç»“æœ
    report_accounts = []
    failed_accounts = []
    
    for report_info in results:
        if not report_info:
            continue
        if report_info[1] == -1:
            failed_accounts.append(report_info)
        else:
            report_accounts.append(report_info)
    
    # é‡è¯•å¤±è´¥çš„è´¦æˆ·
    last_failed_accounts = []
    for account_info in failed_accounts:
        for ac in account_list:
            if ac['account_id'] == account_info[2]:
                report_info = _get_insights((ac, account_info[0]), account_info[3], account_info[4], cfg)
                if report_info[1] != -1:
                    report_accounts.append(report_info)
                else:
                    last_failed_accounts.append(report_info)
    
    if last_failed_accounts:
        helper.sql_error_bot(
            title=f'Facebook spend report',
            text='Facebook failed get_insights\n\n' + str(last_failed_accounts)
        )
    
    # ä¸‹è½½å¹¶ä¿å­˜æŠ¥å‘Š
    for (cat, report_id, account, start_ds_item, ds_item) in report_accounts:
        print(f'   ğŸ“¥ Fetching report for {account}')
        try:
            _fetch_export_report(
                report_id=report_id,
                category=cat,
                params={"account": account, "exec_ds": ds, "start_ds": start_ds_item, "ds": ds_item},
                cfg=cfg
            )
        except Exception as e:
            print(f"   âŒ Failed to fetch report for {account}: {e}")
    
    print(f"\nâœ… Saved {_AD_NETWORK} spend report for {start_ds} to {ds}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. Execution

# COMMAND ----------

print(f"ğŸš€ Starting Job for {_AD_NETWORK} Spend")

try:
    fetch_spend_report_task(ds_param)
    print("\nâœ… Job Finished Successfully")

except Exception as e:
    print(f"\nâŒ Job Failed: {e}")
    # on_failure_callback: å¤±è´¥æ—¶å‘é€é£ä¹¦é€šçŸ¥
    helper.failure_callback(str(e), f"{_AD_NETWORK}_spend_report")
    raise e

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. Data Validation

# COMMAND ----------

env_mode = get_env_mode()
print(f"\nğŸ” Data Validation (ENV_MODE={env_mode})")

helper.validate_and_preview_data(_AD_TYPE, _AD_NETWORK)
