"""
æ•°æ®æ ¼å¼è‡ªåŠ¨è¯†åˆ«ä¸è½¬æ¢æ¨¡å—

æ”¯æŒçš„è¾“å…¥æ ¼å¼ï¼š
- CSV
- JSON Lines (JSONL)  
- JSON æ•°ç»„ [...]
- å•ä¸ª JSON å¯¹è±¡ {...}
- API å“åº”åŒ…è£…æ ¼å¼ {"code": 200, "results": [...], "data": [...]}

æ‰€æœ‰æ ¼å¼ç»Ÿä¸€è½¬æ¢ä¸º JSONL è¾“å‡º
"""

import io
import json
import logging
from enum import Enum
from typing import Iterator, Tuple, List, Any, Optional

import pandas


class DataFormat(Enum):
    """æ•°æ®æ ¼å¼æšä¸¾"""
    CSV = "csv"
    JSONL = "jsonl"
    JSON_ARRAY = "json_array"
    JSON_OBJECT = "json_object"
    API_RESPONSE = "api_response"  # {"code": 200, "results": [...]}
    EMPTY = "empty"
    UNKNOWN = "unknown"


# ============================================================================
# å¸¸è§çš„ API å“åº”æ•°æ®å­—æ®µåï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
# ============================================================================
API_RESPONSE_DATA_KEYS = [
    'results',      # AppLovin: {"code": 200, "results": [...]}
    'data',         # é€šç”¨æ ¼å¼
    'items',        # å¸¸è§æ ¼å¼
    'records',      # å¸¸è§æ ¼å¼
    'rows',         # å¸¸è§æ ¼å¼
    'list',         # å¸¸è§æ ¼å¼
    'content',      # æŸäº› API ä½¿ç”¨
]


# ============================================================================
# Pandas å…¼å®¹æ€§å¤„ç†
# ============================================================================

def _get_read_csv_kwargs() -> dict:
    """æ ¹æ® Pandas ç‰ˆæœ¬è¿”å›æ­£ç¡®çš„é”™è¯¯å¤„ç†å‚æ•°"""
    try:
        pandas_version = tuple(map(int, pandas.__version__.split('.')[:2]))
        if pandas_version >= (1, 3):
            return {'on_bad_lines': 'skip'}
        else:
            return {'error_bad_lines': False}
    except:
        return {'on_bad_lines': 'skip'}


# ============================================================================
# æ ¼å¼æ£€æµ‹
# ============================================================================

def detect_format(text_data: str) -> DataFormat:
    """
    æ™ºèƒ½æ£€æµ‹æ•°æ®æ ¼å¼
    
    Args:
        text_data: åŸå§‹æ–‡æœ¬æ•°æ®
        
    Returns:
        DataFormat: æ£€æµ‹åˆ°çš„æ•°æ®æ ¼å¼
    """
    if not text_data or not text_data.strip():
        return DataFormat.EMPTY
    
    text_stripped = text_data.strip()
    
    # 1. æ£€æŸ¥æ˜¯å¦ä¸º JSON Linesï¼ˆæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼‰
    first_line = text_stripped.split('\n')[0].strip()
    if first_line.startswith('{') and first_line.endswith('}'):
        try:
            json.loads(first_line)
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤šè¡Œï¼Œä¸”æ¯è¡Œéƒ½æ˜¯æœ‰æ•ˆ JSON
            lines = text_stripped.split('\n')
            if len(lines) > 1:
                valid_jsonl = True
                for line in lines[:5]:  # åªæ£€æŸ¥å‰ 5 è¡Œ
                    line = line.strip()
                    if line:
                        try:
                            obj = json.loads(line)
                            if not isinstance(obj, dict):
                                valid_jsonl = False
                                break
                        except json.JSONDecodeError:
                            valid_jsonl = False
                            break
                if valid_jsonl:
                    return DataFormat.JSONL
        except json.JSONDecodeError:
            pass
    
    # 2. æ£€æŸ¥æ˜¯å¦ä¸º JSON æ•°ç»„
    if text_stripped.startswith('['):
        try:
            data = json.loads(text_stripped)
            if isinstance(data, list):
                return DataFormat.JSON_ARRAY
        except json.JSONDecodeError:
            pass
    
    # 3. æ£€æŸ¥æ˜¯å¦ä¸ºå•ä¸ª JSON å¯¹è±¡ï¼ˆåŒ…æ‹¬ API å“åº”ï¼‰
    if text_stripped.startswith('{'):
        try:
            data = json.loads(text_stripped)
            if isinstance(data, dict):
                # æ£€æŸ¥æ˜¯å¦ä¸º API å“åº”åŒ…è£…æ ¼å¼
                if _is_api_response(data):
                    return DataFormat.API_RESPONSE
                return DataFormat.JSON_OBJECT
        except json.JSONDecodeError:
            pass
    
    # 4. é»˜è®¤å°è¯•ä½œä¸º CSV
    return DataFormat.CSV


def _is_api_response(data: dict) -> bool:
    """
    æ£€æµ‹æ˜¯å¦ä¸º API å“åº”åŒ…è£…æ ¼å¼
    
    ç‰¹å¾ï¼š
    - åŒ…å«å¸¸è§çš„æ•°æ®å­—æ®µï¼ˆresults, data, items ç­‰ï¼‰
    - è¯¥å­—æ®µå€¼ä¸ºåˆ—è¡¨
    - å¯èƒ½åŒ…å« code, status, message ç­‰å…ƒæ•°æ®å­—æ®µ
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰å¸¸è§çš„æ•°æ®å­—æ®µ
    for key in API_RESPONSE_DATA_KEYS:
        if key in data and isinstance(data[key], list):
            return True
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ code/status å­—æ®µ + æŸä¸ªåˆ—è¡¨å­—æ®µ
    has_meta = any(k in data for k in ['code', 'status', 'success', 'message', 'msg'])
    has_list_field = any(isinstance(v, list) for v in data.values())
    
    return has_meta and has_list_field


def _extract_data_from_api_response(data: dict) -> Tuple[List[Any], str]:
    """
    ä» API å“åº”ä¸­æå–å®é™…æ•°æ®
    
    Args:
        data: API å“åº”å­—å…¸
        
    Returns:
        Tuple[List[Any], str]: (æå–çš„æ•°æ®åˆ—è¡¨, ä½¿ç”¨çš„å­—æ®µå)
    """
    # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾æ•°æ®å­—æ®µ
    for key in API_RESPONSE_DATA_KEYS:
        if key in data and isinstance(data[key], list):
            return data[key], key
    
    # å¦‚æœæ²¡æ‰¾åˆ°å·²çŸ¥å­—æ®µï¼Œæ‰¾ç¬¬ä¸€ä¸ªåˆ—è¡¨å­—æ®µ
    for key, value in data.items():
        if isinstance(value, list):
            return value, key
    
    # æ²¡æœ‰æ‰¾åˆ°åˆ—è¡¨å­—æ®µï¼Œè¿”å›ç©º
    return [], ''


# ============================================================================
# æ ¼å¼è½¬æ¢
# ============================================================================

def convert_to_jsonl(
    text_data: str, 
    data_format: DataFormat = None,
    date_columns: List[str] = None
) -> Tuple[str, int, DataFormat]:
    """
    å°†å„ç§æ ¼å¼çš„æ•°æ®è½¬æ¢ä¸º JSON Lines
    
    Args:
        text_data: åŸå§‹æ–‡æœ¬æ•°æ®
        data_format: å¯é€‰ï¼ŒæŒ‡å®šæ•°æ®æ ¼å¼ï¼ˆä¸æŒ‡å®šåˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰
        date_columns: éœ€è¦è½¬æ¢ä¸ºå­—ç¬¦ä¸²çš„æ—¥æœŸåˆ—å
        
    Returns:
        Tuple[str, int, DataFormat]: (JSONL å†…å®¹, è¡Œæ•°, æ£€æµ‹åˆ°çš„æ ¼å¼)
    """
    if not text_data or not text_data.strip():
        return '', 0, DataFormat.EMPTY
    
    # è‡ªåŠ¨æ£€æµ‹æ ¼å¼
    if data_format is None:
        data_format = detect_format(text_data)
    
    print(f"   ğŸ“‹ Detected format: {data_format.value}")
    
    if date_columns is None:
        date_columns = ['date', 'report_date', 'start_ds', 'end_ds', 'exc_ds', 'day']
    
    if data_format == DataFormat.JSONL:
        return _convert_jsonl(text_data)
    
    elif data_format == DataFormat.JSON_ARRAY:
        return _convert_json_array(text_data)
    
    elif data_format == DataFormat.API_RESPONSE:
        return _convert_api_response(text_data)
    
    elif data_format == DataFormat.JSON_OBJECT:
        return _convert_json_object(text_data)
    
    elif data_format == DataFormat.CSV:
        return _convert_csv(text_data, date_columns)
    
    else:
        logging.warning(f"   âš ï¸ Unknown format, returning as-is")
        return text_data, 0, DataFormat.UNKNOWN


def _convert_jsonl(text_data: str) -> Tuple[str, int, DataFormat]:
    """å¤„ç† JSON Lines æ ¼å¼"""
    lines = []
    row_count = 0
    for line in text_data.strip().split('\n'):
        line = line.strip()
        if line:
            try:
                json.loads(line)  # éªŒè¯
                lines.append(line)
                row_count += 1
            except json.JSONDecodeError as e:
                logging.warning(f"   âš ï¸ Skipping invalid JSON line: {str(e)[:50]}")
    return '\n'.join(lines), row_count, DataFormat.JSONL


def _convert_json_array(text_data: str) -> Tuple[str, int, DataFormat]:
    """å¤„ç† JSON æ•°ç»„æ ¼å¼"""
    data = json.loads(text_data)
    lines = [json.dumps(item, ensure_ascii=False) for item in data]
    return '\n'.join(lines), len(lines), DataFormat.JSON_ARRAY


def _convert_api_response(text_data: str) -> Tuple[str, int, DataFormat]:
    """å¤„ç† API å“åº”åŒ…è£…æ ¼å¼"""
    data = json.loads(text_data)
    extracted_data, field_name = _extract_data_from_api_response(data)
    
    if not extracted_data:
        # æ²¡æœ‰æ‰¾åˆ°æ•°æ®åˆ—è¡¨ï¼Œå½“ä½œæ™®é€š JSON å¯¹è±¡å¤„ç†
        logging.warning(f"   âš ï¸ No list data found in API response, treating as single object")
        return json.dumps(data, ensure_ascii=False), 1, DataFormat.JSON_OBJECT
    
    print(f"   ğŸ“¦ Extracted {len(extracted_data)} records from '{field_name}' field")
    lines = [json.dumps(item, ensure_ascii=False) for item in extracted_data]
    return '\n'.join(lines), len(lines), DataFormat.API_RESPONSE


def _convert_json_object(text_data: str) -> Tuple[str, int, DataFormat]:
    """å¤„ç†å•ä¸ª JSON å¯¹è±¡"""
    data = json.loads(text_data)
    return json.dumps(data, ensure_ascii=False), 1, DataFormat.JSON_OBJECT


def _convert_csv(text_data: str, date_columns: List[str]) -> Tuple[str, int, DataFormat]:
    """å¤„ç† CSV æ ¼å¼"""
    csv_kwargs = _get_read_csv_kwargs()
    df = pandas.read_csv(io.StringIO(text_data), **csv_kwargs)
    
    # å¤„ç†æ—¥æœŸåˆ—
    for col in date_columns:
        if col in df.columns:
            df[col] = df[col].astype(str)
    
    # è½¬æ¢ä¸º JSONL
    lines = []
    for _, row in df.iterrows():
        record = {col: (None if pandas.isna(val) else val) for col, val in row.items()}
        lines.append(json.dumps(record, ensure_ascii=False))
    
    return '\n'.join(lines), len(lines), DataFormat.CSV


# ============================================================================
# æµå¼è§£æå™¨ï¼ˆç”¨äºå¤§æ–‡ä»¶ï¼‰
# ============================================================================

class StreamingParser:
    """
    æµå¼æ•°æ®è§£æå™¨
    
    ç”¨äºå¤„ç†å¤§æ–‡ä»¶ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜
    """
    
    def __init__(self, chunk_size: int = 10000):
        self.chunk_size = chunk_size
        self.date_columns = ['date', 'report_date', 'start_ds', 'end_ds', 'exc_ds', 'day']
    
    def detect_format_from_file(self, file_obj) -> DataFormat:
        """
        ä»æ–‡ä»¶å¯¹è±¡ä¸­æ£€æµ‹æ ¼å¼
        
        ä¼šè¯»å–æ–‡ä»¶å¼€å¤´çš„ä¸€éƒ¨åˆ†æ¥æ£€æµ‹æ ¼å¼ï¼Œç„¶å seek å›å¼€å¤´
        """
        current_pos = file_obj.tell()
        
        # è¯»å–å¼€å¤´ 4KB æ¥æ£€æµ‹æ ¼å¼
        sample = file_obj.read(4096)
        file_obj.seek(current_pos)
        
        if isinstance(sample, bytes):
            sample = sample.decode('utf-8', errors='ignore')
        
        return detect_format(sample)
    
    def parse_file(self, file_obj, data_format: DataFormat = None) -> Iterator[Tuple[List[dict], int]]:
        """
        æµå¼è§£ææ–‡ä»¶
        
        Args:
            file_obj: æ–‡ä»¶å¯¹è±¡ï¼ˆéœ€è¦æ”¯æŒ read/seekï¼‰
            data_format: å¯é€‰ï¼ŒæŒ‡å®šæ ¼å¼
            
        Yields:
            Tuple[List[dict], int]: (è®°å½•åˆ—è¡¨, å½“å‰æ‰¹æ¬¡å¤§å°)
        """
        if data_format is None:
            data_format = self.detect_format_from_file(file_obj)
        
        print(f"   ğŸ“‹ Detected format: {data_format.value}")
        
        if data_format == DataFormat.CSV:
            yield from self._parse_csv_streaming(file_obj)
        else:
            # å¯¹äº JSON æ ¼å¼ï¼Œå…ˆè¯»å–å…¨éƒ¨å†…å®¹å†è§£æ
            # ï¼ˆå› ä¸º JSON æ ¼å¼ä¸èƒ½çœŸæ­£æµå¼è§£æï¼‰
            yield from self._parse_json_all(file_obj, data_format)
    
    def _parse_csv_streaming(self, file_obj) -> Iterator[Tuple[List[dict], int]]:
        """æµå¼è§£æ CSV"""
        csv_kwargs = _get_read_csv_kwargs()
        csv_kwargs['chunksize'] = self.chunk_size
        
        for chunk_df in pandas.read_csv(file_obj, **csv_kwargs):
            # å¤„ç†æ—¥æœŸåˆ—
            for col in self.date_columns:
                if col in chunk_df.columns:
                    chunk_df[col] = chunk_df[col].astype(str)
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            records = []
            for _, row in chunk_df.iterrows():
                record = {col: (None if pandas.isna(val) else val) for col, val in row.items()}
                records.append(record)
            
            yield records, len(records)
    
    def _parse_json_all(self, file_obj, data_format: DataFormat) -> Iterator[Tuple[List[dict], int]]:
        """è§£æ JSON æ ¼å¼ï¼ˆéæµå¼ï¼Œä½†åˆ†æ‰¹è¿”å›ï¼‰"""
        content = file_obj.read()
        if isinstance(content, bytes):
            content = content.decode('utf-8')
        
        # è½¬æ¢ä¸º JSONL
        jsonl_content, row_count, _ = convert_to_jsonl(content, data_format)
        
        if not jsonl_content:
            return
        
        # åˆ†æ‰¹è¿”å›
        lines = jsonl_content.split('\n')
        batch = []
        
        for line in lines:
            line = line.strip()
            if line:
                try:
                    batch.append(json.loads(line))
                except json.JSONDecodeError:
                    continue
                
                if len(batch) >= self.chunk_size:
                    yield batch, len(batch)
                    batch = []
        
        # è¿”å›å‰©ä½™çš„
        if batch:
            yield batch, len(batch)


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

def parse_response_content(content: bytes, encoding: str = 'utf-8') -> Tuple[str, int, DataFormat]:
    """
    è§£æ HTTP å“åº”å†…å®¹
    
    Args:
        content: å“åº”çš„å­—èŠ‚å†…å®¹
        encoding: ç¼–ç æ ¼å¼
        
    Returns:
        Tuple[str, int, DataFormat]: (JSONL å†…å®¹, è¡Œæ•°, æ ¼å¼)
    """
    text_data = content.decode(encoding)
    return convert_to_jsonl(text_data)


def records_to_jsonl(records: List[dict]) -> str:
    """
    å°†è®°å½•åˆ—è¡¨è½¬æ¢ä¸º JSONL å­—ç¬¦ä¸²
    
    Args:
        records: å­—å…¸åˆ—è¡¨
        
    Returns:
        str: JSONL æ ¼å¼å­—ç¬¦ä¸²
    """
    return '\n'.join(json.dumps(record, ensure_ascii=False) for record in records)
