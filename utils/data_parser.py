"""
æ•°æ®æ ¼å¼è‡ªåŠ¨è¯†åˆ«ä¸è½¬æ¢æ¨¡å—

æ”¯æŒçš„è¾“å…¥æ ¼å¼ï¼š
- CSV
- JSON Lines (JSONL)  
- JSON æ•°ç»„ [...]
- å•ä¸ª JSON å¯¹è±¡ {...}
- API å“åº”åŒ…è£…æ ¼å¼ {"code": 200, "results": [...], "data": [...]}

æ‰€æœ‰æ ¼å¼ç»Ÿä¸€è½¬æ¢ä¸º JSONL è¾“å‡º
"""

import io
import json
import logging
from enum import Enum
from typing import Iterator, Tuple, List, Any, Optional

import pandas


class DataFormat(Enum):
    """æ•°æ®æ ¼å¼æšä¸¾"""
    CSV = "csv"
    JSONL = "jsonl"
    JSON_ARRAY = "json_array"
    JSON_OBJECT = "json_object"
    API_RESPONSE = "api_response"  # {"code": 200, "results": [...]}
    EMPTY = "empty"
    UNKNOWN = "unknown"


# ============================================================================
# å¸¸è§çš„ API å“åº”æ•°æ®å­—æ®µåï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
# ============================================================================
API_RESPONSE_DATA_KEYS = [
    'results',      # AppLovin: {"code": 200, "results": [...]}
    'data',         # é€šç”¨æ ¼å¼
    'items',        # å¸¸è§æ ¼å¼
    'records',      # å¸¸è§æ ¼å¼
    'rows',         # å¸¸è§æ ¼å¼
    'list',         # å¸¸è§æ ¼å¼
    'content',      # æŸäº› API ä½¿ç”¨
]


# ============================================================================
# Pandas å…¼å®¹æ€§å¤„ç†
# ============================================================================

def _get_read_csv_kwargs() -> dict:
    """æ ¹æ® Pandas ç‰ˆæœ¬è¿”å›æ­£ç¡®çš„é”™è¯¯å¤„ç†å‚æ•°"""
    try:
        pandas_version = tuple(map(int, pandas.__version__.split('.')[:2]))
        if pandas_version >= (1, 3):
            return {'on_bad_lines': 'skip'}
        else:
            return {'error_bad_lines': False}
    except:
        return {'on_bad_lines': 'skip'}


# ============================================================================
# æ ¼å¼æ£€æµ‹
# ============================================================================

def detect_format(text_data: str) -> DataFormat:
    """
    æ™ºèƒ½æ£€æµ‹æ•°æ®æ ¼å¼
    
    Args:
        text_data: åŸå§‹æ–‡æœ¬æ•°æ®
        
    Returns:
        DataFormat: æ£€æµ‹åˆ°çš„æ•°æ®æ ¼å¼
    """
    if not text_data or not text_data.strip():
        return DataFormat.EMPTY
    
    text_stripped = text_data.strip()
    
    # 1. æ£€æŸ¥æ˜¯å¦ä¸º JSON Linesï¼ˆæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼‰
    first_line = text_stripped.split('\n')[0].strip()
    if first_line.startswith('{') and first_line.endswith('}'):
        try:
            json.loads(first_line)
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤šè¡Œï¼Œä¸”æ¯è¡Œéƒ½æ˜¯æœ‰æ•ˆ JSON
            lines = text_stripped.split('\n')
            if len(lines) > 1:
                valid_jsonl = True
                for line in lines[:5]:  # åªæ£€æŸ¥å‰ 5 è¡Œ
                    line = line.strip()
                    if line:
                        try:
                            obj = json.loads(line)
                            if not isinstance(obj, dict):
                                valid_jsonl = False
                                break
                        except json.JSONDecodeError:
                            valid_jsonl = False
                            break
                if valid_jsonl:
                    return DataFormat.JSONL
            else:
                # åªæœ‰ä¸€è¡Œï¼Œä¸”æ˜¯æœ‰æ•ˆ JSON å¯¹è±¡
                return DataFormat.JSON_OBJECT
        except json.JSONDecodeError:
            pass
    
    # 2. æ£€æŸ¥æ˜¯å¦ä¸º JSON æ•°ç»„
    if text_stripped.startswith('['):
        try:
            data = json.loads(text_stripped)
            if isinstance(data, list):
                return DataFormat.JSON_ARRAY
        except json.JSONDecodeError:
            pass
    
    # 3. æ£€æŸ¥æ˜¯å¦ä¸ºå•ä¸ª JSON å¯¹è±¡ï¼ˆåŒ…æ‹¬ API å“åº”ï¼‰
    # æ³¨æ„ï¼šå³ä½¿æ˜¯å¤šè¡Œ JSONï¼ˆæ ¼å¼åŒ–çš„ï¼‰ï¼Œä¹Ÿåº”è¯¥å°è¯•è§£æ
    if text_stripped.startswith('{'):
        try:
            data = json.loads(text_stripped)
            if isinstance(data, dict):
                # æ£€æŸ¥æ˜¯å¦ä¸º API å“åº”åŒ…è£…æ ¼å¼
                if _is_api_response(data):
                    return DataFormat.API_RESPONSE
                return DataFormat.JSON_OBJECT
        except json.JSONDecodeError:
            # 4. ã€é‡è¦ã€‘å¯å‘å¼æ£€æµ‹ï¼šå¦‚æœæ˜¯æˆªæ–­çš„ JSONï¼Œé€šè¿‡ç‰¹å¾åˆ¤æ–­
            # è¿™å¯¹äºæµå¼å¤„ç†éå¸¸é‡è¦ï¼Œå› ä¸ºåªè¯»å–äº†éƒ¨åˆ†æ•°æ®
            if _detect_api_response_heuristic(text_stripped):
                return DataFormat.API_RESPONSE
            # æ£€æŸ¥æ˜¯å¦åƒæ˜¯å•ä¸ª JSON å¯¹è±¡ï¼ˆè¢«æˆªæ–­çš„ï¼‰
            if _detect_json_object_heuristic(text_stripped):
                return DataFormat.JSON_OBJECT
    
    # 5. æ›´ä¸¥æ ¼çš„ CSV æ£€æµ‹ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„ CSV ç‰¹å¾
    # - ç¬¬ä¸€è¡ŒåŒ…å«é€—å·åˆ†éš”çš„å­—æ®µå
    # - ä¸ä»¥ { æˆ– [ å¼€å¤´
    if not text_stripped.startswith('{') and not text_stripped.startswith('['):
        lines = text_stripped.split('\n')
        if len(lines) >= 1:
            first_line = lines[0].strip()
            # æ£€æŸ¥æ˜¯å¦æœ‰é€—å·åˆ†éš”çš„å¤šä¸ªå­—æ®µ
            if ',' in first_line or '\t' in first_line:
                return DataFormat.CSV
    
    # 6. æ— æ³•è¯†åˆ«çš„æ ¼å¼
    logging.warning(f"   âš ï¸ Could not detect format. First 100 chars: {text_stripped[:100]}")
    return DataFormat.UNKNOWN


def _detect_api_response_heuristic(text_data: str) -> bool:
    """
    å¯å‘å¼æ£€æµ‹ï¼šåˆ¤æ–­æ˜¯å¦ä¸º API å“åº”æ ¼å¼ï¼ˆå³ä½¿ JSON è¢«æˆªæ–­ï¼‰
    
    ç‰¹å¾ï¼š
    - ä»¥ { å¼€å¤´
    - åŒ…å« "code": æˆ– "status":
    - åŒ…å« "results": æˆ– "data": ç­‰æ•°æ®å­—æ®µ
    """
    # æ£€æŸ¥å¸¸è§çš„ API å“åº”ç‰¹å¾
    has_code = '"code"' in text_data or '"status"' in text_data
    has_data_field = any(f'"{key}"' in text_data for key in API_RESPONSE_DATA_KEYS)
    
    return has_code and has_data_field


def _detect_json_object_heuristic(text_data: str) -> bool:
    """
    å¯å‘å¼æ£€æµ‹ï¼šåˆ¤æ–­æ˜¯å¦ä¸º JSON å¯¹è±¡æ ¼å¼ï¼ˆå³ä½¿è¢«æˆªæ–­ï¼‰
    
    ç‰¹å¾ï¼š
    - ä»¥ { å¼€å¤´
    - åŒ…å« "key": æ ¼å¼çš„é”®å€¼å¯¹
    """
    import re
    # æ£€æŸ¥æ˜¯å¦æœ‰ JSON é”®å€¼å¯¹æ¨¡å¼
    pattern = r'"[a-zA-Z_][a-zA-Z0-9_]*"\s*:'
    return bool(re.search(pattern, text_data))


def _is_api_response(data: dict) -> bool:
    """
    æ£€æµ‹æ˜¯å¦ä¸º API å“åº”åŒ…è£…æ ¼å¼
    
    ç‰¹å¾ï¼š
    - åŒ…å«å¸¸è§çš„æ•°æ®å­—æ®µï¼ˆresults, data, items ç­‰ï¼‰
    - è¯¥å­—æ®µå€¼ä¸ºåˆ—è¡¨
    - å¯èƒ½åŒ…å« code, status, message ç­‰å…ƒæ•°æ®å­—æ®µ
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰å¸¸è§çš„æ•°æ®å­—æ®µ
    for key in API_RESPONSE_DATA_KEYS:
        if key in data and isinstance(data[key], list):
            return True
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ code/status å­—æ®µ + æŸä¸ªåˆ—è¡¨å­—æ®µ
    has_meta = any(k in data for k in ['code', 'status', 'success', 'message', 'msg'])
    has_list_field = any(isinstance(v, list) for v in data.values())
    
    return has_meta and has_list_field


def _extract_data_from_api_response(data: dict) -> Tuple[List[Any], str]:
    """
    ä» API å“åº”ä¸­æå–å®é™…æ•°æ®
    
    Args:
        data: API å“åº”å­—å…¸
        
    Returns:
        Tuple[List[Any], str]: (æå–çš„æ•°æ®åˆ—è¡¨, ä½¿ç”¨çš„å­—æ®µå)
    """
    # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾æ•°æ®å­—æ®µ
    for key in API_RESPONSE_DATA_KEYS:
        if key in data and isinstance(data[key], list):
            return data[key], key
    
    # å¦‚æœæ²¡æ‰¾åˆ°å·²çŸ¥å­—æ®µï¼Œæ‰¾ç¬¬ä¸€ä¸ªåˆ—è¡¨å­—æ®µ
    for key, value in data.items():
        if isinstance(value, list):
            return value, key
    
    # æ²¡æœ‰æ‰¾åˆ°åˆ—è¡¨å­—æ®µï¼Œè¿”å›ç©º
    return [], ''


# ============================================================================
# æ ¼å¼è½¬æ¢
# ============================================================================

def convert_to_jsonl(
    text_data: str, 
    data_format: DataFormat = None,
    date_columns: List[str] = None
) -> Tuple[str, int, DataFormat]:
    """
    å°†å„ç§æ ¼å¼çš„æ•°æ®è½¬æ¢ä¸º JSON Lines
    
    Args:
        text_data: åŸå§‹æ–‡æœ¬æ•°æ®
        data_format: å¯é€‰ï¼ŒæŒ‡å®šæ•°æ®æ ¼å¼ï¼ˆä¸æŒ‡å®šåˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰
        date_columns: éœ€è¦è½¬æ¢ä¸ºå­—ç¬¦ä¸²çš„æ—¥æœŸåˆ—å
        
    Returns:
        Tuple[str, int, DataFormat]: (JSONL å†…å®¹, è¡Œæ•°, æ£€æµ‹åˆ°çš„æ ¼å¼)
    """
    if not text_data or not text_data.strip():
        return '', 0, DataFormat.EMPTY
    
    # è‡ªåŠ¨æ£€æµ‹æ ¼å¼
    if data_format is None:
        data_format = detect_format(text_data)
    
    print(f"   ğŸ“‹ Detected format: {data_format.value}")
    
    if date_columns is None:
        date_columns = ['date', 'report_date', 'start_ds', 'end_ds', 'exc_ds', 'day']
    
    if data_format == DataFormat.JSONL:
        return _convert_jsonl(text_data)
    
    elif data_format == DataFormat.JSON_ARRAY:
        return _convert_json_array(text_data)
    
    elif data_format == DataFormat.API_RESPONSE:
        return _convert_api_response(text_data)
    
    elif data_format == DataFormat.JSON_OBJECT:
        return _convert_json_object(text_data)
    
    elif data_format == DataFormat.CSV:
        return _convert_csv(text_data, date_columns)
    
    else:
        logging.warning(f"   âš ï¸ Unknown format, returning as-is")
        return text_data, 0, DataFormat.UNKNOWN


def _convert_jsonl(text_data: str) -> Tuple[str, int, DataFormat]:
    """å¤„ç† JSON Lines æ ¼å¼"""
    lines = []
    row_count = 0
    for line in text_data.strip().split('\n'):
        line = line.strip()
        if line:
            try:
                json.loads(line)  # éªŒè¯
                lines.append(line)
                row_count += 1
            except json.JSONDecodeError as e:
                logging.warning(f"   âš ï¸ Skipping invalid JSON line: {str(e)[:50]}")
    return '\n'.join(lines), row_count, DataFormat.JSONL


def _convert_json_array(text_data: str) -> Tuple[str, int, DataFormat]:
    """å¤„ç† JSON æ•°ç»„æ ¼å¼"""
    data = json.loads(text_data)
    lines = [json.dumps(item, ensure_ascii=False) for item in data]
    return '\n'.join(lines), len(lines), DataFormat.JSON_ARRAY


def _convert_api_response(text_data: str) -> Tuple[str, int, DataFormat]:
    """å¤„ç† API å“åº”åŒ…è£…æ ¼å¼"""
    data = json.loads(text_data)
    extracted_data, field_name = _extract_data_from_api_response(data)
    
    if not extracted_data:
        # æ²¡æœ‰æ‰¾åˆ°æ•°æ®åˆ—è¡¨ï¼Œå½“ä½œæ™®é€š JSON å¯¹è±¡å¤„ç†
        logging.warning(f"   âš ï¸ No list data found in API response, treating as single object")
        return json.dumps(data, ensure_ascii=False), 1, DataFormat.JSON_OBJECT
    
    print(f"   ğŸ“¦ Extracted {len(extracted_data)} records from '{field_name}' field")
    lines = [json.dumps(item, ensure_ascii=False) for item in extracted_data]
    return '\n'.join(lines), len(lines), DataFormat.API_RESPONSE


def _convert_json_object(text_data: str) -> Tuple[str, int, DataFormat]:
    """å¤„ç†å•ä¸ª JSON å¯¹è±¡"""
    data = json.loads(text_data)
    return json.dumps(data, ensure_ascii=False), 1, DataFormat.JSON_OBJECT


def _convert_csv(text_data: str, date_columns: List[str]) -> Tuple[str, int, DataFormat]:
    """å¤„ç† CSV æ ¼å¼"""
    csv_kwargs = _get_read_csv_kwargs()
    df = pandas.read_csv(io.StringIO(text_data), **csv_kwargs)
    
    # å¤„ç†æ—¥æœŸåˆ—
    for col in date_columns:
        if col in df.columns:
            df[col] = df[col].astype(str)
    
    # è½¬æ¢ä¸º JSONL
    lines = []
    for _, row in df.iterrows():
        record = {col: (None if pandas.isna(val) else val) for col, val in row.items()}
        lines.append(json.dumps(record, ensure_ascii=False))
    
    return '\n'.join(lines), len(lines), DataFormat.CSV


# ============================================================================
# æµå¼è§£æå™¨ï¼ˆç”¨äºå¤§æ–‡ä»¶ï¼‰
# ============================================================================

class StreamingParser:
    """
    æµå¼æ•°æ®è§£æå™¨
    
    ç”¨äºå¤„ç†å¤§æ–‡ä»¶ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜
    """
    
    def __init__(self, chunk_size: int = 10000):
        self.chunk_size = chunk_size
        self.date_columns = ['date', 'report_date', 'start_ds', 'end_ds', 'exc_ds', 'day']
    
    def detect_format_from_file(self, file_obj) -> DataFormat:
        """
        ä»æ–‡ä»¶å¯¹è±¡ä¸­æ£€æµ‹æ ¼å¼
        
        ä¼šè¯»å–æ–‡ä»¶å¼€å¤´çš„ä¸€éƒ¨åˆ†æ¥æ£€æµ‹æ ¼å¼ï¼Œç„¶å seek å›å¼€å¤´
        """
        current_pos = file_obj.tell()
        
        # è¯»å–å¼€å¤´ 4KB æ¥æ£€æµ‹æ ¼å¼
        sample = file_obj.read(4096)
        file_obj.seek(current_pos)
        
        if isinstance(sample, bytes):
            sample = sample.decode('utf-8', errors='ignore')
        
        return detect_format(sample)
    
    def parse_file(self, file_obj, data_format: DataFormat = None) -> Iterator[Tuple[List[dict], int]]:
        """
        æµå¼è§£ææ–‡ä»¶
        
        Args:
            file_obj: æ–‡ä»¶å¯¹è±¡ï¼ˆéœ€è¦æ”¯æŒ read/seekï¼‰
            data_format: å¯é€‰ï¼ŒæŒ‡å®šæ ¼å¼
            
        Yields:
            Tuple[List[dict], int]: (è®°å½•åˆ—è¡¨, å½“å‰æ‰¹æ¬¡å¤§å°)
        """
        if data_format is None:
            data_format = self.detect_format_from_file(file_obj)
        
        print(f"   ğŸ“‹ Detected format: {data_format.value}")
        
        if data_format == DataFormat.CSV:
            yield from self._parse_csv_streaming(file_obj)
        else:
            # å¯¹äº JSON æ ¼å¼ï¼Œå…ˆè¯»å–å…¨éƒ¨å†…å®¹å†è§£æ
            # ï¼ˆå› ä¸º JSON æ ¼å¼ä¸èƒ½çœŸæ­£æµå¼è§£æï¼‰
            yield from self._parse_json_all(file_obj, data_format)
    
    def _parse_csv_streaming(self, file_obj) -> Iterator[Tuple[List[dict], int]]:
        """æµå¼è§£æ CSV"""
        csv_kwargs = _get_read_csv_kwargs()
        csv_kwargs['chunksize'] = self.chunk_size
        
        for chunk_df in pandas.read_csv(file_obj, **csv_kwargs):
            # å¤„ç†æ—¥æœŸåˆ—
            for col in self.date_columns:
                if col in chunk_df.columns:
                    chunk_df[col] = chunk_df[col].astype(str)
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            records = []
            for _, row in chunk_df.iterrows():
                record = {col: (None if pandas.isna(val) else val) for col, val in row.items()}
                records.append(record)
            
            yield records, len(records)
    
    def _parse_json_all(self, file_obj, data_format: DataFormat) -> Iterator[Tuple[List[dict], int]]:
        """è§£æ JSON æ ¼å¼ï¼ˆéæµå¼ï¼Œä½†åˆ†æ‰¹è¿”å›ï¼‰"""
        content = file_obj.read()
        if isinstance(content, bytes):
            content = content.decode('utf-8')
        
        # å¦‚æœæ ¼å¼æ˜¯ UNKNOWNï¼Œé‡æ–°æ£€æµ‹ï¼ˆå› ä¸ºç°åœ¨æœ‰å®Œæ•´æ•°æ®ï¼‰
        if data_format == DataFormat.UNKNOWN:
            data_format = detect_format(content)
            print(f"   ğŸ“‹ Re-detected format with full content: {data_format.value}")
        
        # è½¬æ¢ä¸º JSONL
        jsonl_content, row_count, actual_format = convert_to_jsonl(content, data_format)
        
        if not jsonl_content:
            return
        
        # åˆ†æ‰¹è¿”å›
        lines = jsonl_content.split('\n')
        batch = []
        
        for line in lines:
            line = line.strip()
            if line:
                try:
                    batch.append(json.loads(line))
                except json.JSONDecodeError:
                    continue
                
                if len(batch) >= self.chunk_size:
                    yield batch, len(batch)
                    batch = []
        
        # è¿”å›å‰©ä½™çš„
        if batch:
            yield batch, len(batch)


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

def parse_response_content(content: bytes, encoding: str = 'utf-8') -> Tuple[str, int, DataFormat]:
    """
    è§£æ HTTP å“åº”å†…å®¹
    
    Args:
        content: å“åº”çš„å­—èŠ‚å†…å®¹
        encoding: ç¼–ç æ ¼å¼
        
    Returns:
        Tuple[str, int, DataFormat]: (JSONL å†…å®¹, è¡Œæ•°, æ ¼å¼)
    """
    text_data = content.decode(encoding)
    return convert_to_jsonl(text_data)


def records_to_jsonl(records: List[dict]) -> str:
    """
    å°†è®°å½•åˆ—è¡¨è½¬æ¢ä¸º JSONL å­—ç¬¦ä¸²
    
    Args:
        records: å­—å…¸åˆ—è¡¨
        
    Returns:
        str: JSONL æ ¼å¼å­—ç¬¦ä¸²
    """
    return '\n'.join(json.dumps(record, ensure_ascii=False) for record in records)


# ============================================================================
# AppLovin ä¸“ç”¨è½¬æ¢å™¨
# ============================================================================

def expand_applovin_max_ad_unit(ad_unit_data: dict) -> List[dict]:
    """
    å±•å¼€ AppLovin MAX å¹¿å‘Šå•å…ƒæ•°æ®ä¸­çš„ ad_network_settings
    
    å°†æ¯ä¸ª network setting å±•å¼€ä¸ºå•ç‹¬çš„è¡Œ
    
    è¾“å…¥æ ¼å¼:
    {
        "id": "xxx",
        "name": "...",
        "platform": "ios",
        "ad_format": "INTER",
        "package_name": "com.xxx",
        "disabled": false,
        "ad_network_settings": {
            "UNITY_BIDDING": {"disabled": false, "ad_network_ad_unit_id": "xxx"},
            "ADMOB_BIDDING": {"disabled": false, "ad_network_ad_unit_id": "yyy"},
            ...
        }
    }
    
    è¾“å‡ºæ ¼å¼ (æ¯ä¸ª network ä¸€è¡Œ):
    {"id":"xxx","name":"...","platform":"ios","ad_format":"INTER","package_name":"com.xxx","disabled":false,"network":"UNITY_BIDDING","ad_network_ad_unit_id":"xxx"}
    
    Args:
        ad_unit_data: å¹¿å‘Šå•å…ƒæ•°æ®å­—å…¸
        
    Returns:
        List[dict]: å±•å¼€åçš„è®°å½•åˆ—è¡¨
    """
    # åŸºç¡€å­—æ®µ
    base_fields = ['id', 'name', 'platform', 'ad_format', 'package_name', 'disabled', 'has_active_experiment']
    base_record = {k: ad_unit_data.get(k) for k in base_fields if k in ad_unit_data}
    
    # è·å– ad_network_settings
    ad_network_settings = ad_unit_data.get('ad_network_settings', {})
    
    # å¦‚æœæ²¡æœ‰ network settingsï¼Œè¿”å›åŸºç¡€è®°å½•
    if not ad_network_settings:
        return [base_record]
    
    # å±•å¼€æ¯ä¸ª network setting
    expanded_records = []
    
    # ad_network_settings å¯èƒ½æ˜¯ dict æˆ– list
    if isinstance(ad_network_settings, dict):
        for network_name, network_config in ad_network_settings.items():
            record = base_record.copy()
            record['network'] = network_name
            
            # æå– network é…ç½®ä¸­çš„å­—æ®µ
            if isinstance(network_config, dict):
                record['network_disabled'] = network_config.get('disabled', False)
                record['ad_network_ad_unit_id'] = network_config.get('ad_network_ad_unit_id', '')
                # å¯èƒ½è¿˜æœ‰å…¶ä»–å­—æ®µ
                for key in ['cpm_floor', 'cpm_floor_value']:
                    if key in network_config:
                        record[key] = network_config[key]
            
            expanded_records.append(record)
    
    elif isinstance(ad_network_settings, list):
        # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼
        for network_config in ad_network_settings:
            if isinstance(network_config, dict):
                record = base_record.copy()
                # å°è¯•è·å– network åç§°
                network_name = network_config.get('network') or network_config.get('name') or 'unknown'
                record['network'] = network_name
                record['network_disabled'] = network_config.get('disabled', False)
                record['ad_network_ad_unit_id'] = network_config.get('ad_network_ad_unit_id', '')
                
                expanded_records.append(record)
    
    return expanded_records if expanded_records else [base_record]


def convert_applovin_max_config(text_data: str) -> Tuple[str, int]:
    """
    è½¬æ¢ AppLovin MAX é…ç½® API å“åº”
    
    è‡ªåŠ¨å¤„ç†ï¼š
    1. API å“åº”åŒ…è£…æ ¼å¼ {"code": 200, "results": [...]}
    2. å•ä¸ªå¹¿å‘Šå•å…ƒå¯¹è±¡
    3. å±•å¼€ ad_network_settings
    
    Args:
        text_data: åŸå§‹ API å“åº”æ–‡æœ¬
        
    Returns:
        Tuple[str, int]: (JSONL å†…å®¹, è¡Œæ•°)
    """
    if not text_data or not text_data.strip():
        return '', 0
    
    text_stripped = text_data.strip()
    
    try:
        data = json.loads(text_stripped)
    except json.JSONDecodeError as e:
        logging.error(f"âŒ Failed to parse JSON: {e}")
        return '', 0
    
    all_records = []
    
    # å¦‚æœæ˜¯ API å“åº”åŒ…è£…æ ¼å¼
    if isinstance(data, dict) and _is_api_response(data):
        extracted_data, field_name = _extract_data_from_api_response(data)
        print(f"   ğŸ“¦ Extracted {len(extracted_data)} ad units from '{field_name}' field")
        
        for ad_unit in extracted_data:
            if isinstance(ad_unit, dict):
                all_records.extend(expand_applovin_max_ad_unit(ad_unit))
    
    # å¦‚æœæ˜¯å•ä¸ªå¹¿å‘Šå•å…ƒå¯¹è±¡
    elif isinstance(data, dict):
        all_records.extend(expand_applovin_max_ad_unit(data))
    
    # å¦‚æœæ˜¯å¹¿å‘Šå•å…ƒåˆ—è¡¨
    elif isinstance(data, list):
        for ad_unit in data:
            if isinstance(ad_unit, dict):
                all_records.extend(expand_applovin_max_ad_unit(ad_unit))
    
    if not all_records:
        return '', 0
    
    print(f"   ğŸ“Š Expanded to {len(all_records)} network records")
    lines = [json.dumps(record, ensure_ascii=False) for record in all_records]
    return '\n'.join(lines), len(lines)
